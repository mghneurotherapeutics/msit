{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG Analysis\n",
    "\n",
    "In this notebook we analyze the difference between incongruent and congruent trials in the MSIT EEG data. We look at both the difference in the event-related potentials and in time frequency power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event-Related Potentials\n",
    "\n",
    "Here we analyze the difference between incongruent and congruent event-related potentials (ERPs). ERPs are simply the time domain average of every stimulus presentation and response made. Averaging separately by each condition produces two waveforms that we can compare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Evoked Data\n",
    "\n",
    "In this cell we create the evoked (ERP) data by averaging the epochs data. We make four sets of evoked data. For both the average referenced data and the laplacian transformed data we create evoked data time-locked to the stimulus presentations and the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T20:31:47.390753Z",
     "start_time": "2018-05-18T20:16:18.198627Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "sys.path.append('../src')\n",
    "from utils import select_subjects\n",
    "import pandas as pd\n",
    "from mne import read_epochs, grand_average, write_evokeds, set_log_level\n",
    "import numpy as np\n",
    "\n",
    "set_log_level('critical')\n",
    "\n",
    "# input and output directories\n",
    "preproc_dir = '../data/derivatives/eeg_preprocessing'\n",
    "deriv_dir = '../data/derivatives/eeg_analysis'\n",
    "if not os.path.exists(deriv_dir):\n",
    "    os.makedirs(deriv_dir)\n",
    "\n",
    "# select out the subjects\n",
    "subjects = select_subjects('both')\n",
    "\n",
    "# load config parameters\n",
    "config = json.load(open('experiment_config.json', 'r'))\n",
    "epochs_info = config['epochs_info']\n",
    "\n",
    "for trans_type in ['base', 'laplacian']:\n",
    "    print(trans_type)\n",
    "\n",
    "    for epo_time, epo_type in zip(epochs_info['epo_boundaries'],\n",
    "                                  epochs_info['epo_types']):\n",
    "        print(epo_type)\n",
    "        group_evo = {'incongruent': [], 'congruent': []}\n",
    "        group_data = {'incongruent': [], 'congruent': []}\n",
    "            \n",
    "        for subject in subjects:\n",
    "\n",
    "            # load epochs\n",
    "            if trans_type == 'laplacian':\n",
    "                f = '%s/%s/%s_task-msit_%s_laplacian-epo.fif' \n",
    "            else:\n",
    "                f = '%s/%s/%s_task-msit_%s-epo.fif'\n",
    "            epo = read_epochs(f % (preproc_dir, subject, subject,\n",
    "                                   epo_type), verbose=False)\n",
    "\n",
    "            # crop filter buffer\n",
    "            epo.crop(epo_time[0], epo_time[1])\n",
    "            \n",
    "            # downsample\n",
    "            epo.decimate(5)\n",
    "            \n",
    "            # interpolate bads\n",
    "            epo.interpolate_bads(reset_bads=True)\n",
    "            \n",
    "            # calculate evokeds\n",
    "            evos = [epo[c].average() for c in config['event_types']]\n",
    "\n",
    "            # write evokeds\n",
    "            if not os.path.exists('%s/%s' % (deriv_dir, subject)):\n",
    "                os.makedirs('%s/%s' % (deriv_dir, subject))\n",
    "            if trans_type == 'laplacian':\n",
    "                f = '%s/%s/%s_task-msit_%s_laplacian-ave.fif' \n",
    "            else:\n",
    "                f = '%s/%s/%s_task-msit_%s-ave.fif'\n",
    "            write_evokeds(f % (deriv_dir, subject, subject,\n",
    "                               epo_type), evos) \n",
    "            \n",
    "            # accumulate for group average\n",
    "            for i, c in enumerate(config['event_types']):\n",
    "                evos[i].interpolate_bads(reset_bads=True)\n",
    "                group_evo[c].append(evos[i])\n",
    "                group_data[c].append(evos[i].data * 1e6)\n",
    "                \n",
    "        # calculate and save group evokeds object\n",
    "        evos = [grand_average(group_evo[c]) for c in config['event_types']]\n",
    "        if not os.path.exists('%s/group' %  deriv_dir):\n",
    "            os.makedirs('%s/group' %  deriv_dir)\n",
    "        if trans_type == 'laplacian':\n",
    "            f = '%s/group/group_task-msit_%s_laplacian-ave.fif' \n",
    "        else:\n",
    "            f = '%s/group/group_task-msit_%s-ave.fif'\n",
    "        write_evokeds(f % (deriv_dir, epo_type), evos) \n",
    "        \n",
    "        # calculate and save group evokeds array\n",
    "        data = np.array([group_data[c] for c in config['event_types']])\n",
    "        if trans_type == 'laplacian':\n",
    "            f = '%s/group/group_task-msit_%s_laplacian-ave.npz' \n",
    "        else:\n",
    "            f = '%s/group/group_task-msit_%s-ave.npz'\n",
    "        np.savez_compressed(f % (deriv_dir, epo_type), data=data,\n",
    "                            conditions=config['event_types'],\n",
    "                            times=evos[0].times, chs=evos[0].ch_names,\n",
    "                            subjects=subjects)\n",
    "            \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ERP TFCE Permutation Testing \n",
    "\n",
    "To look at differences between the ERPs for each condition we use <a href=\"https://www.ncbi.nlm.nih.gov/pubmed/23123297\">Threshold Free Cluster Enhancement (TFCE)</a> <a href=\"https://www.ncbi.nlm.nih.gov/pubmed/17517438\">spatiotemporal permutation testing</a>. This approach is very similar to the approach taken with the fMRI except that we now cluster over both time and space as opposed to just space in the fMRI. The technique is performed as follows: \n",
    "\n",
    "1. Our data consists of a # subjects x # channels x # time points array for each condition. We perform a paired t-test for every channel and time point pairing to get a # channels x # time points t-statistic array.\n",
    "2. We use TFCE to pre-enhance the cluster structure of the data by applying the TFCE transform to the t-statistic array.\n",
    "3. Next we permute the data by randomly flipping the signs (and hence the condition labels) of a random subset of subject's condition data. We perform a paired t-test on this permuted data to get a new t-statistic array.\n",
    "4. We use TFCE to enhance the cluster structure of the permuted t-statistics and then we extract the TFCE value with the greatest absolute value to control for multiple comparisons.\n",
    "5. We repeat steps 3 and 4 5000 times to generate a permutation null distribution consisting of the maximum TFCE value across all permutations.\n",
    "6. The permutation p-values are calculated as the percentage of permutation values whose absolute value are greater than the non-permuted TFCE absolute value. This is done for every channel, time point pairing resulting in a # channels x # time points p value array.\n",
    "\n",
    "We complete this process separately for both the stimulus and response epochs with and without the laplacian transform. We use <a href=\"https://www.martinos.org/mne/stable/generated/mne.stats.spatio_temporal_cluster_1samp_test.html#mne.stats.spatio_temporal_cluster_1samp_test\"> MNE's implementation of TFCE spatiotemporal clustering</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T05:11:50.389025Z",
     "start_time": "2018-05-18T21:41:54.493297Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "sys.path.append('../src')\n",
    "from utils import select_subjects\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mne import read_evokeds\n",
    "from mne.channels import find_ch_connectivity\n",
    "from mne.stats import spatio_temporal_cluster_1samp_test as stcluster_test\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "# input and output directories\n",
    "deriv_dir = '../data/derivatives/eeg_analysis'\n",
    "\n",
    "# select out the subjects\n",
    "subjects = select_subjects('both')\n",
    "\n",
    "# get the channel connectivity\n",
    "f = '%s/group/group_task-msit_stimulus_laplacian-ave.fif'\n",
    "evo = read_evokeds(f % deriv_dir, verbose=False)[0]\n",
    "connectivity, ch_names = find_ch_connectivity(evo.info, \n",
    "                                              ch_type='eeg')\n",
    "\n",
    "# load config parameters\n",
    "config = json.load(open('experiment_config.json', 'r'))\n",
    "epochs_info = config['epochs_info']\n",
    "threshold = config['tfce_threshold'] \n",
    "num_perm = config['num_eeg_perm']\n",
    "\n",
    "for trans_type in ['base', 'laplacian']:\n",
    "    print(trans_type)\n",
    "    \n",
    "    for epo_type in epochs_info['epo_types']:\n",
    "        print(epo_type)\n",
    "\n",
    "\n",
    "        # extract the data (incongruent - congruent)\n",
    "        if trans_type == 'laplacian':\n",
    "            f = '%s/group/group_task-msit_%s_laplacian-ave.npz'\n",
    "        else:\n",
    "            f = '%s/group/group_task-msit_%s-ave.npz'\n",
    "            \n",
    "        data = np.load(f % (deriv_dir, epo_type))['data']\n",
    "        data = data[0] - data[1]\n",
    "        data = np.swapaxes(data, 1, 2)\n",
    "\n",
    "        # run threshold free cluster enhancement permutation testing\n",
    "        tfce, _, p_vals, perm_dist = stcluster_test(data, verbose=True,\n",
    "                                                    threshold=threshold,\n",
    "                                                    n_permutations=num_perm,\n",
    "                                                    connectivity=connectivity,\n",
    "                                                    seed=5, n_jobs=10) \n",
    "        p_vals = np.array(p_vals).reshape(tfce.shape)\n",
    "\n",
    "        # save\n",
    "        if trans_type == 'laplacian':\n",
    "            f = '%s/group/group_task-msit_%s_laplacian_tfce.npz'\n",
    "        else:\n",
    "            f = '%s/group/group_task-msit_%s_tfce.npz'\n",
    "        f = f % (deriv_dir, epo_type)\n",
    "        np.savez_compressed(f, tfce=tfce.T, perm_dist=perm_dist, \n",
    "                            chs=evo.ch_names, times=evo.times, \n",
    "                            p_vals=p_vals.T)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize ERPS \n",
    "\n",
    "Here we visualize the group ERPs along with the statistical results. The cell below lets you interactively explore the data. Each parameter setting produces the following:\n",
    "1. An ERP waveform plot on the left:\n",
    "    - The incongruent and congruent conditions are plotted separately with standard error of the mean shading. \n",
    "    - The RT distributions are plotted in the background for the stimulus-locked data. \n",
    "    - Signficant time points for that channel are denoted with a shaded grey background\n",
    "    - A dotted line indicates the time point plotted for the topomap to the right\n",
    "2. An ERP topomap on the right:\n",
    "    - This is the mean incongruent - congruent topomap signal plotted for just the chosen time point\n",
    "    - Colorbar limits are hard to see. They vary from +- 7 uV/mm^2 for laplacian transform to +- 1 uV for non-laplacian transform\n",
    "    - Significant sensors for that timepoint have their names plotted in bold on the topomap\n",
    "\n",
    "Use the following parameter controls to explore the data:\n",
    "- Use the ch parameter to change which channel's ERPs are plotted on the left\n",
    "- Use the trans_type and epo_type parameters to change what type of ERPs are plotted\n",
    "- Use time_ix parameter to change what time point is plotted for the topomap\n",
    "- Use the threshold parameter to change the significance highlighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T16:01:41.073265Z",
     "start_time": "2018-05-23T16:01:39.685713Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7e7187d0b44605b5d71c56631b8f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aW50ZXJhY3RpdmUoY2hpbGRyZW49KERyb3Bkb3duKGRlc2NyaXB0aW9uPXUndHJhbnNfdHlwZScsIG9wdGlvbnM9KCdsYXBsYWNpYW4nLCAnYmFzZScpLCB2YWx1ZT0nbGFwbGFjaWFuJyksIETigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from utils import select_subjects\n",
    "from eeg import visualize_erps, CH_NAMES\n",
    "from ipywidgets import interact, fixed\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "sns.set(font_scale=2, style='whitegrid')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "deriv_dir = '../data/derivatives/eeg_analysis'\n",
    "\n",
    "# load behavior\n",
    "behavior = pd.read_csv('../data/derivatives/behavior/group_data.tsv',\n",
    "                       sep='\\t', na_values='n/a')\n",
    "\n",
    "interact(visualize_erps, deriv_dir=fixed(deriv_dir),\n",
    "         trans_type=['laplacian', 'base'], epo_type=['stimulus', 'response'], \n",
    "         time_ix=(0, 450), ch=CH_NAMES,\n",
    "         threshold=[.001, .01, .05], behavior=fixed(behavior));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of ERP Results\n",
    "\n",
    "We see quite reasonable alignment with <a href=\"https://www.ncbi.nlm.nih.gov/pubmed/28220517\">Gonzalez-Villar and Carillo-de-la-Pena, 2017</a>, one of the few published investigations of EEG in the MSIT task that we use as a reference:\n",
    "- Lower N2 in Cz for incongruent compared to incongruent trials, though the effect is smaller. The midfrontal N2 is often thought of as a marker of cognitive control.\n",
    "- Longer latency and smeared P3 over Pz for incongruent compared to incongruent trials. The P3 is often conceptualized as a marker of mental workload and thus this difference makes sense as the incongruent trials response time distribution extends out past the congruent distribution.\n",
    "\n",
    "Potential Alignment with Wald RT Model:\n",
    "- The Cz N2 effect occurs right around 300-350 ms. This is about equal to the average non-decision times across subjects (~300 ms). One interpretation is that maybe this N2 difference reflects a trial type categorization process and the lower N2 could be a signature of the increased decision boundary we observed in the model for incongruent trials being sent. The rest of the waveforms from this point on also look like two separate diffusion processes where the incongruent one is slower to reach the same threshold due to the lower starting point.\n",
    "- In the response locked Pz data, the difference in ramping seems similar to a potential difference in drift rate with the incongruent having a lower drift rate as found in the behavior model.\n",
    "\n",
    "### Potential Concerns\n",
    "\n",
    "As with the fMRI, the full scalp TFCE method had a similar issue where a lot of the positive activation got lumped into one giant cluster. As a result, the statistics are probably quite misleading and especially a lot of the negative differences got wrongly ignored. I would refrain from interpreting the statistical shading.\n",
    "\n",
    "### Future Directions\n",
    "\n",
    "- Fix the statistics. Figure out how to reduce sensitivity of cluster methods to excessively large clusters or do more pointed hypothesis led statistics.\n",
    "- Look at behavior model correlations with ERPs. Perhaps Cz N2 amplitude difference is correlated with the difference in decision boundary across subjects. Or perhaps the P3 response aligned \"accumulate slope\" difference is correlated with the drift rate difference across subjects.\n",
    "- Take the ERPs to source space and look for the source space signatures of the above. These could then be compared to the fMRI data.\n",
    "- See if any of these ERP signatures predict psychiatric dysfunction or other task-related questionnaire items (cognitive flexibility, impulsivity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-Frequency Power\n",
    "\n",
    "In addition to comparing ERPs, we also look at differences in time-frequency power between the conditions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the TFR Power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the Raw Power\n",
    "\n",
    "To compute the time-frequency power we use morlet wavelet convolution. Morlet wavelet convolution involves taking sinusoids of varying frequencies and windowing them with a gaussian window. These wavelets are then convolved with the data to produce time varying power estimates at the given frequency. Using a set of frequencies produces a time frequency power representation. The other important parameter is how many cycles of each frequency to include in the gaussian window. This parameter determines the temporal and frequency resolution tradeoff. More cycles give greater frequency resolution at the expense of temporal resolution and vice versa.\n",
    "\n",
    "We followed the methods of <a href=\"https://www.ncbi.nlm.nih.gov/pubmed/24068756\">Cohen and Donner, 2013</a>. Specifically, this included frequencies logarithimically spaced from 2-60 with accompanying number of cycles logarithmically spaced from 3-10. The log spacing gives equal weighting to the different frequency bands which are defined on a logarithmic scale. \n",
    "\n",
    "Additionally, following Cohen and Donner's finding that conflict-related theta is non-phase locked, we compute the non-phase locked power here. To do so, we remove the ERP for each condition from every trial separately for each condition. Thus, after the transformation we have a non-phase locked time-frequency representation for every channel, epoch pairing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T09:28:14.116808Z",
     "start_time": "2018-05-19T17:02:46.207945Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from utils import select_subjects\n",
    "from mne.time_frequency import tfr_morlet, write_tfrs\n",
    "import numpy as np\n",
    "from mne import read_epochs, set_log_level\n",
    "\n",
    "set_log_level('critical')\n",
    "\n",
    "subjects = select_subjects('both')\n",
    "\n",
    "preproc_dir = '../data/derivatives/eeg_preprocessing'\n",
    "deriv_dir = '../data/derivatives/eeg_analysis'\n",
    "\n",
    "# select out the subjects\n",
    "subjects = select_subjects('both')\n",
    "\n",
    "# load config parameters\n",
    "config = json.load(open('experiment_config.json', 'r'))\n",
    "epochs_info = config['epochs_info']\n",
    "\n",
    "# match Cohen, Donner 2013 \n",
    "frequencies = np.logspace(np.log10(2), np.log10(60), num=30) \n",
    "n_cycles = np.logspace(np.log10(3), np.log10(10), num=30) \n",
    "\n",
    "for trans_type in ['base', 'laplacian']:\n",
    "    print(trans_type)\n",
    "\n",
    "    for epo_times, epo_type in zip(epochs_info['epo_boundaries'],\n",
    "                                   epochs_info['epo_types']):\n",
    "        print(epo_type)\n",
    "        group_evo = {'incongruent': [], 'congruent': []}\n",
    "        group_data = {'incongruent': [], 'congruent': []}\n",
    "\n",
    "        for subject in subjects:\n",
    "            print(subject)\n",
    "\n",
    "            # load epochs\n",
    "            if trans_type == 'laplacian':\n",
    "                f = '%s/%s/%s_task-msit_%s_laplacian-epo.fif' \n",
    "            else:\n",
    "                f = '%s/%s/%s_task-msit_%s-epo.fif'\n",
    "            epochs = read_epochs(f % (preproc_dir, subject, subject,\n",
    "                                      epo_type), verbose=False)\n",
    "\n",
    "            # interpolate the bad channels\n",
    "            epochs.interpolate_bads(reset_bads=True)\n",
    "\n",
    "            # calculate power\n",
    "            tfrs = []\n",
    "            for event in config['event_types']:\n",
    "                cond_epochs = epochs[event]\n",
    "\n",
    "                # remove evoked response\n",
    "                cond_epochs.subtract_evoked()\n",
    "\n",
    "                # compute tfr\n",
    "                power = tfr_morlet(cond_epochs, freqs=frequencies, \n",
    "                                   n_cycles=n_cycles, decim=5, \n",
    "                                   return_itc=False, average=False, n_jobs=2)\n",
    "\n",
    "                # crop out filter buffer\n",
    "                power.crop(epo_times[0], epo_times[1])\n",
    "                tfrs.append(power)\n",
    "\n",
    "            # save raw tfr\n",
    "            if trans_type == 'laplacian':\n",
    "                f = '%s/%s/%s_task-msit_%s_laplacian_raw-tfr.h5' \n",
    "            else:\n",
    "                f = '%s/%s/%s_task-msit_%s_raw-tfr.h5'\n",
    "                \n",
    "            write_tfrs(f % (deriv_dir, subject, subject, epo_type), tfrs, \n",
    "                       overwrite=True)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Normalize\n",
    "\n",
    "Raw TFR power is difficult to work with since it is highly dependent on the magnitude of the signal. This poses two problems:\n",
    "1. Lower frequencies are inherently higher magnitude than higher frequencies and thus higher frequencies will be masked by the lower frequencies.\n",
    "2. Subject's data comes at varying magnitudes, but we want to compare task-related changes across subjects.\n",
    "\n",
    "To alleviate these issues, we baseline normalize the data. We use a baseline period of -.5 to -.1 s prior to stimulus presentation. We use the <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3183439/\"> Grandchamp and Delorme baseline normalization method</a> which involves:\n",
    "- First each trial is normalized by the mean power across the entire trial.\n",
    "- The data is averaged acrossed trials\n",
    "- The baseline normalization value is calculated by taking the mean of the baseline period for each channel and frequency.\n",
    "- The data for each channel and frequency is normalized by dividing by this value.\n",
    "- The data are log transformed and multiplied by 10.\n",
    "\n",
    "Thus, the power data now ranges from -inf to +inf where a value of 1 corresponds to a 100% increase in power relative to baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T10:16:53.737075Z",
     "start_time": "2018-05-20T09:28:17.348355Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from utils import select_subjects\n",
    "from eeg import baseline_normalize \n",
    "import numpy as np\n",
    "from mne.time_frequency import tfr_morlet, read_tfrs, write_tfrs\n",
    "from mne import grand_average\n",
    "\n",
    "subjects = select_subjects('both')\n",
    "\n",
    "preproc_dir = '../data/derivatives/eeg_preprocessing'\n",
    "deriv_dir = '../data/derivatives/eeg_analysis'\n",
    "\n",
    "# select out the subjects\n",
    "subjects = select_subjects('both')\n",
    "\n",
    "# load config parameters\n",
    "config = json.load(open('experiment_config.json', 'r'))\n",
    "epochs_info = config['epochs_info']\n",
    "baseline_bounds = epochs_info['baseline_boundary']\n",
    "\n",
    "# cache stimulus baseline periods \n",
    "baselines = {}\n",
    "\n",
    "for trans_type in ['base', 'laplacian']:\n",
    "    print(trans_type)\n",
    "    \n",
    "    for epo_time, epo_type in zip(epochs_info['epo_boundaries'],\n",
    "                                  epochs_info['epo_types']):\n",
    "        print(epo_type)\n",
    "\n",
    "        group = {'incongruent': [], 'congruent': []}\n",
    "        \n",
    "        for subject in subjects:\n",
    "            \n",
    "            print(subject)\n",
    "\n",
    "            if trans_type == 'laplacian':\n",
    "                f = '%s/%s/%s_task-msit_%s_laplacian_raw-tfr.h5'\n",
    "            else:\n",
    "                f = '%s/%s/%s_task-msit_%s_raw-tfr.h5'\n",
    "            tfrs = read_tfrs(f % (deriv_dir, subject, subject, epo_type))\n",
    "\n",
    "            if epo_type == 'stimulus':\n",
    "                baselines[subject] = {'incongruent': baseline_bounds, \n",
    "                                      'congruent': baseline_bounds}\n",
    "\n",
    "            norm_tfrs = []\n",
    "            for i, c in enumerate(config['event_types']):\n",
    "\n",
    "                tfr, baseline = baseline_normalize(tfrs[i], \n",
    "                                                   baselines[subject][c],\n",
    "                                                   func=np.mean, \n",
    "                                                   method='grandchamp')\n",
    "                norm_tfrs.append(tfr)\n",
    "                group[c].append(tfr)\n",
    "                baselines[subject][c] = baseline\n",
    "\n",
    "\n",
    "            if trans_type == 'laplacian':\n",
    "                f = '%s/%s/%s_task-msit_%s_laplacian_norm-tfr.h5'\n",
    "            else:\n",
    "                f = '%s/%s/%s_task-msit_%s_norm-tfr.h5'\n",
    "            write_tfrs(f % (deriv_dir, subject, subject, epo_type), \n",
    "                       norm_tfrs, overwrite=True)\n",
    "\n",
    "        group_tfrs = [grand_average(group[c]) for c in config['event_types']]\n",
    "        if trans_type == 'laplacian':\n",
    "            f = '%s/group/group_task-msit_%s_laplacian_norm-tfr.h5'\n",
    "        else:\n",
    "            f = '%s/group/group_task-msit_%s_norm-tfr.h5'\n",
    "        write_tfrs(f % (deriv_dir, epo_type), group_tfrs, overwrite=True)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Band Power\n",
    "\n",
    "Finally, we compute power band data. Given the high dimensionality of tfr power data, it is often useful to reduce the full frequency range to frequency bands of interest. We define theta as 3-7 Hz, alpha as 7.5-12.5 Hz, and beta as 15-30 Hz. The band power is obtained by simpling averaging the normalized power across all frequencies that lie within a band's range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T15:13:00.130847Z",
     "start_time": "2018-05-22T15:06:34.615194Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from utils import select_subjects\n",
    "from eeg import baseline_normalize \n",
    "import numpy as np\n",
    "from mne.time_frequency import tfr_morlet, read_tfrs, write_tfrs\n",
    "from mne import grand_average\n",
    "\n",
    "subjects = select_subjects('both')\n",
    "\n",
    "preproc_dir = '../data/derivatives/eeg_preprocessing'\n",
    "deriv_dir = '../data/derivatives/eeg_analysis'\n",
    "\n",
    "# select out the subjects\n",
    "subjects = select_subjects('both')\n",
    "\n",
    "# load config parameters\n",
    "config = json.load(open('experiment_config.json', 'r'))\n",
    "epochs_info = config['epochs_info']\n",
    "bands = config['power_bands']\n",
    "\n",
    "# cache stimulus baseline periods \n",
    "baselines = {}\n",
    "\n",
    "for trans_type in ['base', 'laplacian']:\n",
    "    print(trans_type)\n",
    "    \n",
    "    for epo_time, epo_type in zip(epochs_info['epo_boundaries'],\n",
    "                                  epochs_info['epo_types']):\n",
    "        print(epo_type)\n",
    "\n",
    "        group = {}\n",
    "        for band in bands.keys():\n",
    "            group[band] = {'incongruent': [], 'congruent': []}\n",
    "        \n",
    "        for subject in subjects:\n",
    "            print(subject)\n",
    "            if trans_type == 'laplacian':\n",
    "                f = '%s/%s/%s_task-msit_%s_laplacian_norm-tfr.h5'\n",
    "            else:\n",
    "                f = '%s/%s/%s_task-msit_%s_norm-tfr.h5'\n",
    "            tfrs = read_tfrs(f % (deriv_dir, subject, subject, epo_type))\n",
    "            \n",
    "            sub_data = {}\n",
    "            for band in bands.keys():\n",
    "                sub_data[band] = []\n",
    "\n",
    "                times = tfrs[0].times\n",
    "                chs = tfrs[0].ch_names\n",
    "                freqs = tfrs[0].freqs\n",
    "                band_ix = np.where(np.logical_and(freqs >= bands[band][0],\n",
    "                                                  freqs <= bands[band][1]))[0]\n",
    "                for i, c in enumerate(config['event_types']):\n",
    "                    data = tfrs[i].data[:, band_ix, :].mean(axis=1)\n",
    "                    group[band][c].append(data)\n",
    "                    sub_data[band].append(data)\n",
    "\n",
    "            if trans_type == 'laplacian':\n",
    "                f = '%s/%s/%s_task-msit_%s_laplacian_band-tfr.npz'\n",
    "            else:\n",
    "                f = '%s/%s/%s_task-msit_%s_band-tfr.npz'\n",
    "            np.savez_compressed(f % (deriv_dir, subject, subject, epo_type),\n",
    "                                chs=chs, conditions=config['event_types'],\n",
    "                                freqs=freqs, times=times, \n",
    "                                theta=np.array(sub_data['theta']),\n",
    "                                beta=np.array(sub_data['beta']),\n",
    "                                alpha=np.array(sub_data['alpha']))\n",
    "            \n",
    "        group_bands = {}\n",
    "        for band in bands.keys():\n",
    "            group_bands[band] = []\n",
    "            for c in config['event_types']:\n",
    "                group_bands[band].append(np.array(group[band][c]))\n",
    "                \n",
    "        if trans_type == 'laplacian':\n",
    "            f = '%s/group/group_task-msit_%s_laplacian_band-tfr.npz'\n",
    "        else:\n",
    "            f = '%s/group/group_task-msit_%s_band-tfr.npz'\n",
    "        np.savez_compressed(f % (deriv_dir, epo_type),\n",
    "                            chs=chs, conditions=config['event_types'],\n",
    "                            freqs=freqs, times=times, subjects=subjects,\n",
    "                            theta=np.array(group_bands['theta']),\n",
    "                            beta=np.array(group_bands['beta']),\n",
    "                            alpha=np.array(group_bands['alpha']))\n",
    "        del group\n",
    "        del group_bands\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFR Band Power TFCE Permutation Testing\n",
    "\n",
    "The permutation process is exactly the same as the ERP permutation testing except here we additionally split by power band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T07:36:26.810325Z",
     "start_time": "2018-05-22T18:55:08.644277Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "sys.path.append('../src')\n",
    "from utils import select_subjects\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mne import read_evokeds\n",
    "from mne.channels import find_ch_connectivity\n",
    "from mne.stats import spatio_temporal_cluster_1samp_test as stcluster_test\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "# input and output directories\n",
    "deriv_dir = '../data/derivatives/eeg_analysis'\n",
    "\n",
    "# select out the subjects\n",
    "subjects = select_subjects('both')\n",
    "\n",
    "# get the channel connectivity\n",
    "f = '%s/group/group_task-msit_stimulus_laplacian-ave.fif'\n",
    "evo = read_evokeds(f % deriv_dir, verbose=False)[0]\n",
    "connectivity, ch_names = find_ch_connectivity(evo.info, \n",
    "                                              ch_type='eeg')\n",
    "\n",
    "# load config parameters\n",
    "config = json.load(open('experiment_config.json', 'r'))\n",
    "epochs_info = config['epochs_info']\n",
    "threshold = config['tfce_threshold'] \n",
    "num_perm = config['num_eeg_perm']\n",
    "\n",
    "for trans_type in ['base', 'laplacian']:\n",
    "    print(trans_type)\n",
    "    \n",
    "    for epo_type in epochs_info['epo_types']:\n",
    "        print(epo_type)\n",
    "\n",
    "\n",
    "        # extract the data (incongruent - congruent)\n",
    "        if trans_type == 'laplacian':\n",
    "            band_f = '%s/group/group_task-msit_%s_laplacian_band-tfr.npz'\n",
    "        else:\n",
    "            band_f = '%s/group/group_task-msit_%s_band-tfr.npz'\n",
    "        \n",
    "        for band in config['power_bands'].keys(): \n",
    "            print(band)\n",
    "            \n",
    "            data = np.load(band_f % (deriv_dir, epo_type))[band]\n",
    "            data = data[0] - data[1]\n",
    "            data = np.swapaxes(data, 1, 2)\n",
    "\n",
    "            # run threshold free cluster enhancement permutation testing\n",
    "            tfce, _, p_vals, perm_dist = stcluster_test(data, verbose=True,\n",
    "                                                        threshold=threshold,\n",
    "                                                        n_permutations=num_perm,\n",
    "                                                        connectivity=connectivity,\n",
    "                                                        seed=5, n_jobs=10) \n",
    "            p_vals = np.array(p_vals).reshape(tfce.shape)\n",
    "\n",
    "            # save\n",
    "            if trans_type == 'laplacian':\n",
    "                f = '%s/group/group_task-msit_%s_%s_laplacian_tfce.npz'\n",
    "            else:\n",
    "                f = '%s/group/group_task-msit_%s_%s_tfce.npz'\n",
    "            f = f % (deriv_dir, epo_type, band)\n",
    "            np.savez_compressed(f, tfce=tfce.T, perm_dist=perm_dist, \n",
    "                                chs=evo.ch_names, times=evo.times, \n",
    "                                p_vals=p_vals.T)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize TFR Power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFR Heatmaps\n",
    "\n",
    "The below cell plots tfr power heatmaps interactively. One can cycle through what subject to plot, the channel to plot, the color limits for the heat map, as well as whether to look at laplacian vs. non-laplacian transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T14:10:09.194351Z",
     "start_time": "2018-05-23T14:10:03.298386Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "989d9ba6bf594b87af6ae63a46e42ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aW50ZXJhY3RpdmUoY2hpbGRyZW49KERyb3Bkb3duKGRlc2NyaXB0aW9uPXUnc3ViamVjdCcsIG9wdGlvbnM9KCdncm91cCcsICdzdWItaGMwMDEnLCAnc3ViLWhjMDAyJywgJ3N1Yi1oYzAwMyfigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from utils import select_subjects\n",
    "from eeg import visualize_tfr_heatmap, CH_NAMES\n",
    "from ipywidgets import interact, fixed\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import json\n",
    "sns.set(font_scale=2, style='whitegrid')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "subjects = ['group'] + select_subjects('both')\n",
    "\n",
    "with open('experiment_config.json', 'r') as fid:\n",
    "    config = json.load(fid)\n",
    "\n",
    "deriv_dir = '../data/derivatives/eeg_analysis'\n",
    "\n",
    "# load behavior\n",
    "behavior = pd.read_csv('../data/derivatives/behavior/group_data.tsv',\n",
    "                       sep='\\t', na_values='n/a')\n",
    "\n",
    "interact(visualize_tfr_heatmap, deriv_dir=fixed(deriv_dir), subject=subjects,\n",
    "         trans_type=['laplacian', 'base'], ch=CH_NAMES, lim=(0, 3, .1),\n",
    "         behavior=fixed(behavior), config=fixed(config));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Band Power \n",
    "\n",
    "Here we visualize the group band power along with the statistical results. The cell below lets you interactively explore the data. Each parameter setting produces the following:\n",
    "1. A band power waveform plot on the left:\n",
    "    - The incongruent and congruent conditions are plotted separately with standard error of the mean shading. \n",
    "    - The RT distributions are plotted in the background for the stimulus-locked data. \n",
    "    - Signficant time points for that channel are denoted with a shaded grey background\n",
    "    - A dotted line indicates the time point plotted for the topomap to the right\n",
    "2. A band power topomap on the right:\n",
    "    - This is the mean incongruent - congruent topomap signal plotted for just the chosen time point\n",
    "    - Colorbar limits are hard to see. They vary from +- 1 dB \n",
    "    - Significant sensors for that timepoint have their names plotted in bold on the topomap\n",
    "\n",
    "Use the following parameter controls to explore the data:\n",
    "- Use the ch parameter to change which channel's ERPs are plotted on the left\n",
    "- Use the trans_type and epo_type parameters to change what type of ERPs are plotted\n",
    "- Use time_ix parameter to change what time point is plotted for the topomap\n",
    "- Use the threshold parameter to change the significance highlighting\n",
    "- Use the band parameter to change the frequency band plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T14:10:36.455309Z",
     "start_time": "2018-05-23T14:10:34.013346Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b652518fd23c412f96e357213f1813ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aW50ZXJhY3RpdmUoY2hpbGRyZW49KERyb3Bkb3duKGRlc2NyaXB0aW9uPXUndHJhbnNfdHlwZScsIG9wdGlvbnM9KCdsYXBsYWNpYW4nLCAnYmFzZScpLCB2YWx1ZT0nbGFwbGFjaWFuJyksIETigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from utils import select_subjects\n",
    "from eeg import visualize_band_power, CH_NAMES\n",
    "from ipywidgets import interact, fixed\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pandas as pd\n",
    "sns.set(font_scale=2, style='whitegrid')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "with open('experiment_config.json', 'r') as fid:\n",
    "    config = json.load(fid)\n",
    "bands = config['power_bands']\n",
    "\n",
    "# load behavior\n",
    "behavior = pd.read_csv('../data/derivatives/behavior/group_data.tsv',\n",
    "                       sep='\\t', na_values='n/a')\n",
    "\n",
    "deriv_dir = '../data/derivatives/eeg_analysis'\n",
    "interact(visualize_band_power, deriv_dir=fixed(deriv_dir),\n",
    "         trans_type=['laplacian', 'base'], epo_type=['stimulus', 'response'], \n",
    "         time_ix=(0, 450), ch=CH_NAMES, band=['theta', 'alpha', 'beta'],\n",
    "         threshold=[.001, .01, .05], behavior=fixed(behavior));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Power Results\n",
    "\n",
    "Again, we see reasonable alignment with <a href=\"https://www.ncbi.nlm.nih.gov/pubmed/28220517\">Gonzalez-Villar and Carillo-de-la-Pena, 2017</a>, one of the few published investigations of EEG in the MSIT task that we use as a reference:\n",
    "- Greater midfrontal theta for incongruent compared to congruent trials. This seems to be concentrated above FCz for us as opposed to Cz for them. We found a similarly low theta (~2.5-7 Hz rather than a more common 4-8 Hz).\n",
    "- A greater reduction in alpha for incongruent compared to congruent trials, especially concentrated over the parietal/occipital areas. This is clearly in line with incongruent trials requiring greater sustained attention as alpha is often regarded as a marker of attention/alertness.\n",
    "- We also see reduced beta power in the incongruent vs. congruent trials over the central electrodes. As noted by Gonzalez-Villar, this could reflect greater sustained motor preparation for incongruent compared to congruent trials.\n",
    "\n",
    "Alignment with RT Model Parameters:\n",
    "- The FCz theta difference looks as if it could reflect a difference in decision boundary. One possibility is that this difference could be correlated with the decision boundary difference. This would make the case that the midfrontal theta accumulation represents some method of evidence accumulation or directed effort towards evidence accumulation.\n",
    "- The occipital alpha difference could be related to the difference in drift rate. As alpha can be thought of as a proxy for attention, a greater reduction in alpha could be correlated with a slower drift rate in incongruent trials compared to congruent trials reflecting the added difficulty in accumulating information for incongruent trials. \n",
    "\n",
    "### Potential Concerns\n",
    "\n",
    "- The same concerns with the TFCE statistical approach apply here though the issue appears to be less pronounced.\n",
    "- Arbritrary drawing of power bands. We use the Gonzalez-Villar and Cohen papers to inform our power band limits, however as revealed with the heatmaps, the power differences are often fairly complex. One might look at attemping to uncover differences in the 2D power space rather than the 1D band space to get a more complete picture of the differences.\n",
    "\n",
    "### Future Directions\n",
    "\n",
    "- Fix the statistics.\n",
    "- Look at behavior RT model correlations with power signatures.\n",
    "- Source localize the band power and look for the source space signatures of these difference frequency band differences. It could also be interesting to compare spatially to the fMRI.\n",
    "- Look for connectivity dynamics. Perhaps midfrontal theta serves as a control signal to parietal based accumulation and this could be reflected by theta coherence between the two.\n",
    "- See if any of these power band signatures predict psychiatric dysfunction or other task-related questionnaire items (cognitive flexibility, impulsivity).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "856px",
    "left": "0px",
    "right": "1482.91px",
    "top": "110px",
    "width": "336px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
