{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-03T20:47:07.691739Z",
     "start_time": "2018-01-03T20:47:05.626870Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/autofs/space/cassia_001/users/matt/software/anaconda2.7/envs/msit/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "from grabbit import Layout\n",
    "from mne import read_epochs, grand_average, write_evokeds, read_evokeds\n",
    "from mne import pick_types, combine_evoked, set_log_level, grand_average\n",
    "from mne.time_frequency import tfr_morlet, read_tfrs, write_tfrs\n",
    "from mne.viz import plot_compare_evokeds\n",
    "from mne.channels import find_ch_connectivity\n",
    "from utils import CH_NAMES, select_subjects, drop_bad_trials\n",
    "from eeg_sensor_analysis import baseline_normalize, power_heatmap, add_events\n",
    "from surface_laplacian import surface_laplacian\n",
    "from mne.stats import spatio_temporal_cluster_1samp_test\n",
    "from mne.stats.cluster_level import _find_clusters, _setup_connectivity, _reshape_clusters, _cluster_indices_to_mask\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ipywidgets import interact, fixed\n",
    "import statsmodels.api as sm\n",
    "from mne.viz import plot_topomap\n",
    "from mne import find_layout\n",
    "from mne.stats import ttest_1samp_no_p\n",
    "\n",
    "sns.set(style='whitegrid', font_scale=2)\n",
    "colors = ['#e41a1c', '#377eb8', '#4daf4a', '#984ea3']\n",
    "set_log_level('critical')\n",
    "\n",
    "# load subjects to process\n",
    "layout = Layout('../data', '../data/grabbit_config.json')\n",
    "subjects = select_subjects('eeg')\n",
    "\n",
    "# Analysis Parameters \n",
    "conditions = ['incongruent', 'congruent']\n",
    "epoch_types = ['stimulus', 'response']\n",
    "epoch_times = [(-.5, 1.75), (-1, 1)]\n",
    "baseline = (-.5, -.1)\n",
    "# match Cohen, Donner 2013 \n",
    "frequencies = np.logspace(np.log10(2), np.log10(60), num=30) \n",
    "n_cycles = np.logspace(np.log10(3), np.log10(10), num=30) \n",
    "\n",
    "# load behavior\n",
    "behavior = pd.read_csv('../data/derivatives/behavior/group_data.tsv', \n",
    "                       na_values='n/a', sep='\\t') \n",
    "behavior = behavior[behavior.modality == 'eeg']\n",
    "\n",
    "# make eeg_sensor derivative directory structure\n",
    "pipeline_root = '../data/derivatives/eeg_sensor'\n",
    "if not os.path.exists(pipeline_root):\n",
    "    os.makedirs(pipeline_root)\n",
    "if not os.path.exists('%s/stats' % pipeline_root):\n",
    "    os.makedirs('%s/stats' % pipeline_root)\n",
    "for subject in subjects + ['group']:\n",
    "    if not os.path.exists('%s/%s' % (pipeline_root, subject)):\n",
    "        os.makedirs('%s/%s' % (pipeline_root, subject))\n",
    "    if not os.path.exists('%s/%s/evoked' % (pipeline_root, subject)):\n",
    "        os.makedirs('%s/%s/evoked' % (pipeline_root, subject))\n",
    "    if not os.path.exists('%s/%s/tfr' % (pipeline_root, subject)):\n",
    "        os.makedirs('%s/%s/tfr' % (pipeline_root, subject))\n",
    "    if not os.path.exists('%s/%s/lap' % (pipeline_root, subject)):\n",
    "        os.makedirs('%s/%s/lap' % (pipeline_root, subject))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surface Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-22T19:04:03.393818Z",
     "start_time": "2017-12-22T18:19:30.457895Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stimulus\n",
      "sub-hc001\n",
      "sub-hc002\n",
      "sub-hc003\n",
      "sub-hc004\n",
      "sub-hc005\n",
      "sub-hc006\n",
      "sub-hc007\n",
      "sub-hc008\n",
      "sub-hc009\n",
      "sub-hc010\n",
      "sub-hc011\n",
      "sub-hc012\n",
      "sub-hc014\n",
      "sub-hc015\n",
      "sub-hc016\n",
      "sub-hc017\n",
      "sub-hc019\n",
      "sub-hc020\n",
      "sub-hc021\n",
      "sub-hc022\n",
      "sub-hc023\n",
      "sub-hc024\n",
      "sub-hc025\n",
      "sub-hc026\n",
      "sub-hc028\n",
      "sub-hc029\n",
      "sub-hc030\n",
      "sub-hc031\n",
      "sub-hc032\n",
      "sub-hc033\n",
      "sub-hc034\n",
      "sub-hc035\n",
      "sub-hc036\n",
      "sub-hc037\n",
      "sub-hc042\n",
      "sub-hc044\n",
      "sub-hc045\n",
      "sub-pp001\n",
      "sub-pp002\n",
      "sub-pp003\n",
      "sub-pp004\n",
      "sub-pp005\n",
      "sub-pp006\n",
      "sub-pp007\n",
      "sub-pp008\n",
      "sub-pp009\n",
      "sub-pp010\n",
      "sub-pp011\n",
      "sub-pp012\n",
      "sub-pp013\n",
      "sub-pp014\n",
      "sub-pp015\n",
      "sub-pp016\n",
      "response\n",
      "sub-hc001\n",
      "sub-hc002\n",
      "sub-hc003\n",
      "sub-hc004\n",
      "sub-hc005\n",
      "sub-hc006\n",
      "sub-hc007\n",
      "sub-hc008\n",
      "sub-hc009\n",
      "sub-hc010\n",
      "sub-hc011\n",
      "sub-hc012\n",
      "sub-hc014\n",
      "sub-hc015\n",
      "sub-hc016\n",
      "sub-hc017\n",
      "sub-hc019\n",
      "sub-hc020\n",
      "sub-hc021\n",
      "sub-hc022\n",
      "sub-hc023\n",
      "sub-hc024\n",
      "sub-hc025\n",
      "sub-hc026\n",
      "sub-hc028\n",
      "sub-hc029\n",
      "sub-hc030\n",
      "sub-hc031\n",
      "sub-hc032\n",
      "sub-hc033\n",
      "sub-hc034\n",
      "sub-hc035\n",
      "sub-hc036\n",
      "sub-hc037\n",
      "sub-hc042\n",
      "sub-hc044\n",
      "sub-hc045\n",
      "sub-pp001\n",
      "sub-pp002\n",
      "sub-pp003\n",
      "sub-pp004\n",
      "sub-pp005\n",
      "sub-pp006\n",
      "sub-pp007\n",
      "sub-pp008\n",
      "sub-pp009\n",
      "sub-pp010\n",
      "sub-pp011\n",
      "sub-pp012\n",
      "sub-pp013\n",
      "sub-pp014\n",
      "sub-pp015\n",
      "sub-pp016\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "coord_file = '../data/eeg_spherical_coordinates.txt'\n",
    "coords = pd.read_csv(coord_file, names=['num', 'ch', 'x', 'y', 'z'], sep=',')\n",
    "x, y, z = np.array(coords.x), np.array(coords.y), np.array(coords.z)\n",
    "\n",
    "epo_root = '../data/derivatives/eeg_preprocessing'\n",
    "for epo_type, epo_times in zip(epoch_types, epoch_times):\n",
    "    print(epo_type)\n",
    "    \n",
    "    group = {'incongruent': [], 'congruent': []}\n",
    "    \n",
    "    for subject in subjects:\n",
    "        if subject == 'group':\n",
    "            continue\n",
    "        print(subject)\n",
    "            \n",
    "        # load subject epochs & behavior\n",
    "        f = '%s/%s/epochs/%s_%s_cleaned-epo.fif' % (epo_root, subject,\n",
    "                                                    subject, epo_type)\n",
    "        epochs = read_epochs(f, verbose=False)\n",
    "        sub_behavior = behavior[behavior.participant_id == subject]\n",
    "        \n",
    "        lap_epochs = surface_laplacian(epochs, x, y, z, 'epochs')\n",
    "        \n",
    "        f = '%s/%s/lap/%s_%s_lap-epo.fif' % (pipeline_root, subject, subject,\n",
    "                                             epo_type)\n",
    "        lap_epochs.save(f)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Evoked Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-22T19:22:06.895782Z",
     "start_time": "2017-12-22T19:04:06.409440Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base\n",
      "stimulus\n",
      "sub-hc001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/autofs/space/cassia_001/users/matt/software/anaconda2.7/envs/msit/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-hc002\n",
      "sub-hc003\n",
      "sub-hc004\n",
      "sub-hc005\n",
      "sub-hc006\n",
      "sub-hc007\n",
      "sub-hc008\n",
      "sub-hc009\n",
      "sub-hc010\n",
      "sub-hc011\n",
      "sub-hc012\n",
      "sub-hc014\n",
      "sub-hc015\n",
      "sub-hc016\n",
      "sub-hc017\n",
      "sub-hc019\n",
      "sub-hc020\n",
      "sub-hc021\n",
      "sub-hc022\n",
      "sub-hc023\n",
      "sub-hc024\n",
      "sub-hc025\n",
      "sub-hc026\n",
      "sub-hc028\n",
      "sub-hc029\n",
      "sub-hc030\n",
      "sub-hc031\n",
      "sub-hc032\n",
      "sub-hc033\n",
      "sub-hc034\n",
      "sub-hc035\n",
      "sub-hc036\n",
      "sub-hc037\n",
      "sub-hc042\n",
      "sub-hc044\n",
      "sub-hc045\n",
      "sub-pp001\n",
      "sub-pp002\n",
      "sub-pp003\n",
      "sub-pp004\n",
      "sub-pp005\n",
      "sub-pp006\n",
      "sub-pp007\n",
      "sub-pp008\n",
      "sub-pp009\n",
      "sub-pp010\n",
      "sub-pp011\n",
      "sub-pp012\n",
      "sub-pp013\n",
      "sub-pp014\n",
      "sub-pp015\n",
      "sub-pp016\n",
      "response\n",
      "sub-hc001\n",
      "sub-hc002\n",
      "sub-hc003\n",
      "sub-hc004\n",
      "sub-hc005\n",
      "sub-hc006\n",
      "sub-hc007\n",
      "sub-hc008\n",
      "sub-hc009\n",
      "sub-hc010\n",
      "sub-hc011\n",
      "sub-hc012\n",
      "sub-hc014\n",
      "sub-hc015\n",
      "sub-hc016\n",
      "sub-hc017\n",
      "sub-hc019\n",
      "sub-hc020\n",
      "sub-hc021\n",
      "sub-hc022\n",
      "sub-hc023\n",
      "sub-hc024\n",
      "sub-hc025\n",
      "sub-hc026\n",
      "sub-hc028\n",
      "sub-hc029\n",
      "sub-hc030\n",
      "sub-hc031\n",
      "sub-hc032\n",
      "sub-hc033\n",
      "sub-hc034\n",
      "sub-hc035\n",
      "sub-hc036\n",
      "sub-hc037\n",
      "sub-hc042\n",
      "sub-hc044\n",
      "sub-hc045\n",
      "sub-pp001\n",
      "sub-pp002\n",
      "sub-pp003\n",
      "sub-pp004\n",
      "sub-pp005\n",
      "sub-pp006\n",
      "sub-pp007\n",
      "sub-pp008\n",
      "sub-pp009\n",
      "sub-pp010\n",
      "sub-pp011\n",
      "sub-pp012\n",
      "sub-pp013\n",
      "sub-pp014\n",
      "sub-pp015\n",
      "sub-pp016\n",
      "laplacian\n",
      "stimulus\n",
      "sub-hc001\n",
      "sub-hc002\n",
      "sub-hc003\n",
      "sub-hc004\n",
      "sub-hc005\n",
      "sub-hc006\n",
      "sub-hc007\n",
      "sub-hc008\n",
      "sub-hc009\n",
      "sub-hc010\n",
      "sub-hc011\n",
      "sub-hc012\n",
      "sub-hc014\n",
      "sub-hc015\n",
      "sub-hc016\n",
      "sub-hc017\n",
      "sub-hc019\n",
      "sub-hc020\n",
      "sub-hc021\n",
      "sub-hc022\n",
      "sub-hc023\n",
      "sub-hc024\n",
      "sub-hc025\n",
      "sub-hc026\n",
      "sub-hc028\n",
      "sub-hc029\n",
      "sub-hc030\n",
      "sub-hc031\n",
      "sub-hc032\n",
      "sub-hc033\n",
      "sub-hc034\n",
      "sub-hc035\n",
      "sub-hc036\n",
      "sub-hc037\n",
      "sub-hc042\n",
      "sub-hc044\n",
      "sub-hc045\n",
      "sub-pp001\n",
      "sub-pp002\n",
      "sub-pp003\n",
      "sub-pp004\n",
      "sub-pp005\n",
      "sub-pp006\n",
      "sub-pp007\n",
      "sub-pp008\n",
      "sub-pp009\n",
      "sub-pp010\n",
      "sub-pp011\n",
      "sub-pp012\n",
      "sub-pp013\n",
      "sub-pp014\n",
      "sub-pp015\n",
      "sub-pp016\n",
      "response\n",
      "sub-hc001\n",
      "sub-hc002\n",
      "sub-hc003\n",
      "sub-hc004\n",
      "sub-hc005\n",
      "sub-hc006\n",
      "sub-hc007\n",
      "sub-hc008\n",
      "sub-hc009\n",
      "sub-hc010\n",
      "sub-hc011\n",
      "sub-hc012\n",
      "sub-hc014\n",
      "sub-hc015\n",
      "sub-hc016\n",
      "sub-hc017\n",
      "sub-hc019\n",
      "sub-hc020\n",
      "sub-hc021\n",
      "sub-hc022\n",
      "sub-hc023\n",
      "sub-hc024\n",
      "sub-hc025\n",
      "sub-hc026\n",
      "sub-hc028\n",
      "sub-hc029\n",
      "sub-hc030\n",
      "sub-hc031\n",
      "sub-hc032\n",
      "sub-hc033\n",
      "sub-hc034\n",
      "sub-hc035\n",
      "sub-hc036\n",
      "sub-hc037\n",
      "sub-hc042\n",
      "sub-hc044\n",
      "sub-hc045\n",
      "sub-pp001\n",
      "sub-pp002\n",
      "sub-pp003\n",
      "sub-pp004\n",
      "sub-pp005\n",
      "sub-pp006\n",
      "sub-pp007\n",
      "sub-pp008\n",
      "sub-pp009\n",
      "sub-pp010\n",
      "sub-pp011\n",
      "sub-pp012\n",
      "sub-pp013\n",
      "sub-pp014\n",
      "sub-pp015\n",
      "sub-pp016\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for epo_class in ['base', 'laplacian']:\n",
    "    print(epo_class)\n",
    "    \n",
    "    if epo_class == 'base':\n",
    "        epo_root = '../data/derivatives/eeg_preprocessing/%s/epochs/%s_%s_cleaned-epo.fif'\n",
    "    else:\n",
    "        epo_root = '../data/derivatives/eeg_sensor/%s/lap/%s_%s_lap-epo.fif'\n",
    "        \n",
    "    for epo_type, epo_times in zip(epoch_types, epoch_times):\n",
    "        print(epo_type)\n",
    "\n",
    "        group = {'incongruent': [], 'congruent': []}\n",
    "\n",
    "        for subject in subjects:\n",
    "            if subject == 'group':\n",
    "                continue\n",
    "\n",
    "            print(subject)\n",
    "\n",
    "            # load subject epochs & behavior\n",
    "            epo_file = epo_root % (subject, subject, epo_type)\n",
    "            epochs = read_epochs(epo_file, verbose=False)\n",
    "            sub_behavior = behavior[behavior.participant_id == subject]\n",
    "\n",
    "            # crop filter period\n",
    "            epochs.crop(epo_times[0], epo_times[1])\n",
    "\n",
    "            # drop bad trials from epochs and behavior\n",
    "            sub_behavior, epochs = drop_bad_trials(subject, sub_behavior,\n",
    "                                                   epochs, layout, epo_type)\n",
    "\n",
    "            # add event labels\n",
    "            epochs = add_events(epochs, sub_behavior)\n",
    "\n",
    "            # interpolate bads\n",
    "            bads = epochs.info['bads']\n",
    "            epochs.interpolate_bads(reset_bads=True)\n",
    "\n",
    "            # extract evoked and standard error\n",
    "            evos = [epochs[c].average() for c in conditions]\n",
    "            evos_std = [epochs[c].standard_error() for c in conditions]\n",
    "\n",
    "            # save evoked and standard error\n",
    "            f = '%s/%s/evoked/%s_%s_%s-ave.fif' % (pipeline_root, subject,\n",
    "                                                   subject, epo_type, epo_class)\n",
    "            write_evokeds(f, evos)\n",
    "            f = '%s/%s/evoked/%s_%s_%s_stderr-ave.fif' % (pipeline_root, subject,\n",
    "                                                           subject, epo_type, epo_class)\n",
    "            write_evokeds(f, evos_std)\n",
    "\n",
    "            # accumulate group data\n",
    "            for i, c in enumerate(conditions):\n",
    "                group[c].append(evos[i])\n",
    "\n",
    "        # accumulate group data\n",
    "        evos = []\n",
    "        evos_std = []\n",
    "        for i, c in enumerate(conditions):\n",
    "            evos.append(grand_average(group[c]))\n",
    "\n",
    "            # compute group standard error\n",
    "            tmp = np.array([e.data for e in group[c]])\n",
    "            tmp = np.std(tmp, axis=0) / np.sqrt(tmp.shape[0])\n",
    "\n",
    "            # place group standard error in evoked object\n",
    "            std_err = evos[i].copy()\n",
    "            std_err.data = tmp.squeeze()\n",
    "            evos_std.append(std_err)\n",
    "\n",
    "        # save group evoked and standard error\n",
    "        f = '%s/group/evoked/group_%s_%s-ave.fif' % (pipeline_root, epo_type,\n",
    "                                                     epo_class)\n",
    "        write_evokeds(f, evos)\n",
    "        f = '%s/group/evoked/group_%s_%s_stderr-ave.fif' % (pipeline_root, \n",
    "                                                            epo_type,\n",
    "                                                            epo_class)\n",
    "        write_evokeds(f, evos_std)\n",
    "\n",
    "del group\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFCE Permutation Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-03T12:22:29.848746Z",
     "start_time": "2018-01-03T01:17:47.642970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stimulus\n",
      "stat_fun(H1): min=-7.425959 max=7.981014\n",
      "Running initial clustering\n",
      "Using 80 thresholds from 0.00 to 7.90 for TFCE computation (h_power=2.00, e_power=0.50)\n",
      "Found 157570 clusters\n",
      "Permuting 4999 times...\n",
      "[......................................  ] 96.19238 \\    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   3 out of  10 | elapsed: 340.9min remaining: 795.4min\n",
      "[Parallel(n_jobs=10)]: Done   6 out of  10 | elapsed: 345.8min remaining: 230.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing cluster p-values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed: 350.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "response\n",
      "stat_fun(H1): min=-8.123451 max=6.875219\n",
      "Running initial clustering\n",
      "Using 82 thresholds from 0.00 to 8.10 for TFCE computation (h_power=2.00, e_power=0.50)\n",
      "Found 140070 clusters\n",
      "Permuting 4999 times...\n",
      "[......................................  ] 96.19238 \\    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   3 out of  10 | elapsed: 301.4min remaining: 703.3min\n",
      "[Parallel(n_jobs=10)]: Done   6 out of  10 | elapsed: 303.9min remaining: 202.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing cluster p-values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed: 312.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "threshold = {'step': .1, 'start': 0}\n",
    "\n",
    "# load ch_connectivity\n",
    "epo_type = 'stimulus'\n",
    "f = '%s/group/evoked/group_%s_laplacian-ave.fif' % (pipeline_root, epo_type)\n",
    "evokeds = read_evokeds(f, verbose=False)\n",
    "evokeds[0].interpolate_bads(reset_bads=True)\n",
    "connectivity, ch_names = find_ch_connectivity(evokeds[0].info, ch_type='eeg')\n",
    "\n",
    "for epo_type in epoch_types:\n",
    "    print(epo_type)\n",
    "    \n",
    "    # accumalate group data\n",
    "    group = []\n",
    "    for subject in subjects:\n",
    "        if subject == 'group':\n",
    "            continue\n",
    "\n",
    "        f = '%s/%s/evoked/%s_%s_laplacian-ave.fif' % (pipeline_root, subject,\n",
    "                                                      subject, epo_type)\n",
    "        evos = read_evokeds(f, verbose=False)\n",
    "        diff = evos[0].data - evos[1].data\n",
    "        group.append(diff.T)\n",
    "        \n",
    "    X = np.array(group)\n",
    "    \n",
    "    # spatio-temporal cluster testing\n",
    "    tfce, _, cluster_ps, perm_dist = spatio_temporal_cluster_1samp_test(X, verbose=True,\n",
    "                                                                        threshold=threshold,\n",
    "                                                                        n_permutations=5000, \n",
    "                                                                        connectivity=connectivity,\n",
    "                                                                        seed=5, \n",
    "                                                                        n_jobs=10) \n",
    "\n",
    "    cluster_ps = np.array(cluster_ps).reshape(tfce.shape).T\n",
    "    tfce = tfce.T\n",
    "    np.savez_compressed('%s/stats/%s_stats.npz' % (pipeline_root, epo_type), \n",
    "                        X=X, connectivity=connectivity, tfce=tfce,\n",
    "                        cluster_ps=cluster_ps,\n",
    "                        perm_dist=perm_dist)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-03T20:47:53.397372Z",
     "start_time": "2018-01-03T20:47:52.638293Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAERCAYAAABYTYH2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXlRSFAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbc2c73ad10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3000660721\n"
     ]
    }
   ],
   "source": [
    "stats = np.load('%s/stats/stimulus_stats.npz' % pipeline_root)\n",
    "cluster_ps = stats['cluster_ps']\n",
    "tfce = stats['tfce']\n",
    "X = stats['X']\n",
    "t = ttest_1samp_no_p(X).T\n",
    "sig = cluster_ps < .05\n",
    "plt.hist(t[sig], bins=20)\n",
    "# plt.hist(t, bins=20)\n",
    "plt.show()\n",
    "print(np.abs(t[sig]).min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-03T20:55:40.601115Z",
     "start_time": "2018-01-03T20:55:40.276608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ac57a11ef849c39f012e4e937c1432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(Dropdown(description=u'ix', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69), value=0), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.check_p>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfcef = tfce[sig].flatten()\n",
    "psf = cluster_ps[sig].flatten()\n",
    "def check_p(ix):\n",
    "    \n",
    "    perm_dist = stats['perm_dist']\n",
    "    plt.hist(perm_dist, bins=25)\n",
    "    plt.axvline(tfcef[ix])\n",
    "    plt.title('p=%.4f' % psf[ix])\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "interact(check_p, ix=np.arange(len(tfce)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-03T20:40:21.789618Z",
     "start_time": "2018-01-03T20:40:21.012534Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_clusters(tfce_ps, ts, threshold):\n",
    "    \n",
    "    n_chs, n_times = tfce_ps.shape\n",
    "    n_tests = n_chs * n_times\n",
    "    \n",
    "    tfce_ps = tfce_ps.T.flatten()\n",
    "    ts = ts.T.flatten() \n",
    "    cluster_info = {}\n",
    "    \n",
    "    # load connectivity matrix\n",
    "    f = '%s/group/evoked/group_stimulus_laplacian-ave.fif' % (pipeline_root)\n",
    "    evokeds = read_evokeds(f, verbose=False)\n",
    "    evokeds[0].interpolate_bads(reset_bads=True)\n",
    "    connectivity, ch_names = find_ch_connectivity(evokeds[0].info, ch_type='eeg')\n",
    "    connectivity = _setup_connectivity(connectivity, n_tests, n_times)\n",
    "    \n",
    "    # extract clusters\n",
    "    \n",
    "    # find positive clusters\n",
    "    pos_ps = tfce_ps.copy()\n",
    "    pos_ps[np.where(ts < 0)[0]] = 1\n",
    "    clusters, _ = _find_clusters(pos_ps, threshold, tail=-1,\n",
    "                                 connectivity=connectivity)\n",
    "    clusters = _cluster_indices_to_mask(clusters, n_tests)\n",
    "    clusters = _reshape_clusters(clusters, (n_times, n_chs))\n",
    "    cum_clusters = [c.T for c in clusters]\n",
    "    \n",
    "    # find negative clusters\n",
    "    neg_ps = tfce_ps.copy()\n",
    "    neg_ps[np.where(ts > 0)[0]] = 1\n",
    "    clusters, _ = _find_clusters(neg_ps, threshold, tail=-1,\n",
    "                                 connectivity=connectivity)\n",
    "    clusters = _cluster_indices_to_mask(clusters, n_tests)\n",
    "    clusters = _reshape_clusters(clusters, (n_times, n_chs))\n",
    "    cum_clusters += [c.T for c in clusters]\n",
    "    \n",
    "    cluster_info['clusters'] = cum_clusters\n",
    "    \n",
    "    cluster_info['spatial_extent'] = []\n",
    "    cluster_info['temporal_extent'] = []\n",
    "    cluster_info['spatial_index'] = []\n",
    "    cluster_info['temporal_index'] = []\n",
    "    cluster_info['smoothed_clusters'] = []\n",
    "    for c in cluster_info['clusters']:\n",
    "        se = c.any(axis=1)\n",
    "        se_ix = np.where(se)[0]\n",
    "        se_ixx = np.where(np.logical_not(se))[0]\n",
    "        se = se.sum()\n",
    "        te = c.any(axis=0)\n",
    "        te_ix = np.where(te)[0]\n",
    "        te_ixx = np.where(np.logical_not(te))[0]\n",
    "        te = te.sum()\n",
    "        smoothed_c = c.copy()\n",
    "        smoothed_c[:, :] = True \n",
    "        smoothed_c[se_ixx, :] = False\n",
    "        smoothed_c[:, te_ixx] = False\n",
    "        \n",
    "        cluster_info['spatial_extent'].append(se)\n",
    "        cluster_info['temporal_extent'].append(te)\n",
    "        cluster_info['spatial_index'].append(se_ix)\n",
    "        cluster_info['temporal_index'].append(te_ix)\n",
    "        cluster_info['smoothed_clusters'].append(smoothed_c)\n",
    "    \n",
    "    return cluster_info\n",
    "    \n",
    "cluster_info = extract_clusters(cluster_ps, t, .00025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mne.viz import plot_topomap\n",
    "\n",
    "def plot_tfce_ps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Subject ERP Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Group ERPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-03T14:29:00.129858Z",
     "start_time": "2018-01-03T14:28:57.364744Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_erps(subject, ch, epo_class, behavior, threshold):\n",
    "    \n",
    "    plt.close('all')\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(24, 6), sharey=True)\n",
    "    \n",
    "    # remove bad trials from behavior\n",
    "    exclusions = ['fast_rt', 'no_response', 'error', 'post_error']\n",
    "    behavior = behavior.loc[np.where(np.sum(behavior[exclusions], \n",
    "                                            axis=1) == 0)[0], :]\n",
    "    if subject != 'group':\n",
    "        behavior = behavior.loc[behavior.participant_id == subject, :]\n",
    "    \n",
    "    \n",
    "    for i, epo_type in enumerate(epoch_types):\n",
    "        ax = axs[i]\n",
    "        \n",
    "        # load evoked with standard error \n",
    "        f = '%s/%s/evoked/%s_%s_%s-ave.fif' % (pipeline_root, subject,\n",
    "                                               subject, epo_type, epo_class)\n",
    "        evos = read_evokeds(f, verbose=False)\n",
    "        f = '%s/%s/evoked/%s_%s_%s_stderr-ave.fif' % (pipeline_root, subject,\n",
    "                                               subject, epo_type, epo_class)\n",
    "        evos_std = read_evokeds(f, verbose=False)\n",
    "        \n",
    "        # load clusters\n",
    "        f = '%s/stats/%s_stats.npz' % (pipeline_root, epo_type)\n",
    "        stats = np.load(f)\n",
    "\n",
    "        X = stats['X']\n",
    "        tfce = stats['tfce']\n",
    "        cluster_ps = stats['cluster_ps']\n",
    "\n",
    "        ch_ix = evos[0].ch_names.index(ch)\n",
    "        times = evos[0].times\n",
    "        ps = cluster_ps[ch_ix, :]\n",
    "        for i, p in enumerate(ps):\n",
    "            if p < threshold:\n",
    "                ax.axvline(times[i], color='k', alpha=0.02, \n",
    "                           label='_nolegend_')\n",
    "\n",
    "        for j, c in enumerate(conditions):\n",
    "            \n",
    "            evo = evos[j]\n",
    "            evo_std = evos_std[j]\n",
    "            \n",
    "            # select out chosen channel\n",
    "            evo.pick_channels([ch])\n",
    "            evo_std.pick_channels([ch])\n",
    "            \n",
    "            # extract the data and standard error\n",
    "            times = evo.times \n",
    "            data = evo.data.squeeze() * 1e6\n",
    "            std_err = evo_std.data.squeeze() * 1e6\n",
    "            \n",
    "            # plot waveforms with standard error shading\n",
    "            ax.plot(times, data, color=colors[j])\n",
    "            ax.fill_between(times, data - std_err, data + std_err,\n",
    "                            alpha=0.5, color=colors[j])\n",
    "            \n",
    "            \n",
    "        # histogram rts on bottom of stimulus-locked plots\n",
    "        for j, c in enumerate(conditions):\n",
    "            \n",
    "            if epo_type == 'stimulus':\n",
    "                bottom=ax.get_ylim()[0]\n",
    "                rt = behavior[behavior.trial_type == c].response_time\n",
    "                ax.hist(rt, color=colors[j], alpha=0.2, \n",
    "                        normed=True, bottom=bottom)\n",
    "            \n",
    "        # set time axis ticks\n",
    "        if epo_type == 'stimulus':\n",
    "            ax.set_xticks(np.arange(-.5, 1.8, .25))\n",
    "            ax.set_xlim((-.5, 1.75))\n",
    "            if epo_class == 'base':\n",
    "                ax.set_ylabel('$\\mu V$')\n",
    "            else:\n",
    "                ax.set_ylabel('$\\mu V / mm^2$')\n",
    "        else:\n",
    "            ax.set_xticks(np.arange(-1, 1.1, .25))\n",
    "        \n",
    "        # plot flourishes\n",
    "        ax.set_title('%s-locked' % epo_type)\n",
    "        ax.axvline(0, color='k')\n",
    "        ax.axhline(0, color='k')\n",
    "        ax.set_xlabel('Time (s)')\n",
    "        ax.legend(conditions, loc='best')\n",
    "    \n",
    "    plt.suptitle('%s %s %s ERPs' % (subject, ch, epo_class), y=1.05)\n",
    "    sns.despine()\n",
    "    plt.show();\n",
    "\n",
    "interact(plot_erps, subject=subjects, ch=CH_NAMES, \n",
    "         epo_class=['base', 'laplacian'], behavior=fixed(behavior),\n",
    "         threshold=[.001, .005, .01, .05]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Topomaps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T19:00:33.735246Z",
     "start_time": "2017-12-28T19:00:28.479915Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b1c8bcf6e344f99a3dcf974fc78dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(Dropdown(description=u'subject', options=('group', 'group', 'sub-hc001', 'sub-hc002', 'sub-hc003', 'sub-hc004', 'sub-hc005', 'sub-hc006', 'sub-hc007', 'sub-hc008', 'sub-hc009', 'sub-hc010', 'sub-hc011', 'sub-hc012', 'sub-hc014', 'sub-hc015', 'sub-hc016', 'sub-hc017', 'sub-hc019', 'sub-hc020', 'sub-hc021', 'sub-hc022', 'sub-hc023', 'sub-hc024', 'sub-hc025', 'sub-hc026', 'sub-hc028', 'sub-hc029', 'sub-hc030', 'sub-hc031', 'sub-hc032', 'sub-hc033', 'sub-hc034', 'sub-hc035', 'sub-hc036', 'sub-hc037', 'sub-hc042', 'sub-hc044', 'sub-hc045', 'sub-pp001', 'sub-pp002', 'sub-pp003', 'sub-pp004', 'sub-pp005', 'sub-pp006', 'sub-pp007', 'sub-pp008', 'sub-pp009', 'sub-pp010', 'sub-pp011', 'sub-pp012', 'sub-pp013', 'sub-pp014', 'sub-pp015', 'sub-pp016'), value='group'), Dropdown(description=u'epo_type', options=('response', 'stimulus'), value='response'), Dropdown(description=u'epo_class', options=('base', 'laplacian'), value='base'), Dropdown(description=u'condition', options=('incongruent', 'congruent', 'i-c'), value='incongruent'), Dropdown(description=u'col_limit', options=(0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5), value=0.5), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_topomap(subject, epo_type, epo_class, condition, col_limit):\n",
    "    plt.close('all')\n",
    "    \n",
    "    if epo_class == 'laplacian':\n",
    "        col_limit *= 10\n",
    "    \n",
    "    # load evoked \n",
    "    f = '%s/%s/evoked/%s_%s_%s-ave.fif' % (pipeline_root, subject,\n",
    "                                           subject, epo_type, epo_class)\n",
    "    evokeds = read_evokeds(f, verbose=False)\n",
    "    \n",
    "    if epo_type == 'stimulus':\n",
    "        times = np.arange(-.1, 1.5, .05)\n",
    "    else:\n",
    "        times = np.arange(-.8, .801, .05)\n",
    "    \n",
    "    if condition == 'incongruent':\n",
    "        evo = evokeds[0]\n",
    "    elif condition == 'congruent':\n",
    "        evo = evokeds[1]\n",
    "    else:\n",
    "        evo = combine_evoked(evokeds, weights=[1, -1])\n",
    "        \n",
    "    n_rows = len(times) // 5 + 1\n",
    "    f, axs = plt.subplots(n_rows, 5, figsize=(20, 14)) \n",
    "    \n",
    "    for i in range(n_rows):\n",
    "        ax_times = times[i * 5:(i + 1) * 5]\n",
    "        axes = axs[i, :len(ax_times)]\n",
    "        evo.plot_topomap(times=ax_times, axes=axes, colorbar=False, \n",
    "                         show=False, vmin=-col_limit, vmax=col_limit)\n",
    "        \n",
    "    plt.suptitle('%s %s %s %s ERP Topomaps (Col Lim: +- %.1f 20)' % (subject,\n",
    "                                                         epo_class,\n",
    "                                                         epo_type,\n",
    "                                                         condition,\n",
    "                                                         col_limit), y=1.05)\n",
    "    plt.show();\n",
    "\n",
    "interact(plot_topomap, subject=['group'] + subjects, \n",
    "         epo_type=['response', 'stimulus'],\n",
    "         epo_class=['base', 'laplacian'],\n",
    "         condition=['incongruent', 'congruent', 'i-c'],\n",
    "         col_limit=np.arange(.5, 5, .5),\n",
    "         diff_col_limit=np.arange(.5, 5, .5));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize TFCE Clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-03T20:40:24.779640Z",
     "start_time": "2018-01-03T20:40:24.682262Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epo_type = 'stimulus'\n",
    "\n",
    "# load evoked \n",
    "f = '%s/group/evoked/group_%s_laplacian-ave.fif' % (pipeline_root, epo_type)\n",
    "evokeds = read_evokeds(f, verbose=False)\n",
    "evo = combine_evoked(evokeds, weights=[1, -1])\n",
    "times = evo.times\n",
    "\n",
    "# load clusters\n",
    "f = '%s/stats/%s_stats.npz' % (pipeline_root, epo_type)\n",
    "stats = np.load(f)\n",
    "cluster_ps = stats['cluster_ps']\n",
    "\n",
    "cluster_ix = np.arange(len(cluster_info['clusters']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-03T20:40:26.357003Z",
     "start_time": "2018-01-03T20:40:25.300973Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf679a33359a4915ac1e176f5ee35c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(Dropdown(description=u'cluster_ix', options=(0, 1, 2, 3), value=0), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.viz_cluster>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def viz_cluster(cluster_ix):\n",
    "    \n",
    "    cluster_mask = cluster_info['clusters'][cluster_ix]\n",
    "    cluster_mask = cluster_mask[:, 0]\n",
    "    cluster_mask[:] = False\n",
    "    te = cluster_info['temporal_extent'][cluster_ix]\n",
    "    se = cluster_info['spatial_extent'][cluster_ix]\n",
    "    tix = cluster_info['temporal_index'][cluster_ix]\n",
    "    six = cluster_info['spatial_index'][cluster_ix]\n",
    "    \n",
    "    f, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    \n",
    "    i_data = evokeds[0].data[six, :].mean(axis=0) * 1e6\n",
    "    c_data = evokeds[1].data[six, :].mean(axis=0) * 1e6\n",
    "    axs[1].plot(times, i_data, colors[0])\n",
    "    axs[1].plot(times, c_data, colors[1])\n",
    "    axs[1].set_xlim((times[0], times[-1]))\n",
    "    \n",
    "    clim = np.max(np.abs(i_data - c_data))\n",
    "    \n",
    "    for ix in tix:\n",
    "        axs[1].axvline(times[ix], color='k', label='_nolegend_', alpha=.02)\n",
    "        \n",
    "    tf = evo.data[:, tix].squeeze().mean(axis=-1) * 1e6\n",
    "    pos = find_layout(evo.info).pos\n",
    "    mask = cluster_mask.copy()\n",
    "    mask[six] = True\n",
    "    image, _ = plot_topomap(tf, pos, mask=mask, show=False, \n",
    "                            vmin=-clim, vmax=clim, axes=axs[0])\n",
    "    \n",
    "    plt.suptitle('%s Cluster #%d: Spatial Extent = %d chs, Temporal Extent = %d ms' % (epo_type, cluster_ix + 1, se, te),\n",
    "                 y=1.03)\n",
    "#     plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "interact(viz_cluster, cluster_ix=cluster_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFR Power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make TFR Power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Raw TFR Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-23T16:01:35.744880Z",
     "start_time": "2017-12-22T19:22:10.500982Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base\n",
      "stimulus\n",
      "sub-hc001\n",
      "sub-hc002\n",
      "sub-hc003\n",
      "sub-hc004\n",
      "sub-hc005\n",
      "sub-hc006\n",
      "sub-hc007\n",
      "sub-hc008\n",
      "sub-hc009\n",
      "sub-hc010\n",
      "sub-hc011\n",
      "sub-hc012\n",
      "sub-hc014\n",
      "sub-hc015\n",
      "sub-hc016\n",
      "sub-hc017\n",
      "sub-hc019\n",
      "sub-hc020\n",
      "sub-hc021\n",
      "sub-hc022\n",
      "sub-hc023\n",
      "sub-hc024\n",
      "sub-hc025\n",
      "sub-hc026\n",
      "sub-hc028\n",
      "sub-hc029\n",
      "sub-hc030\n",
      "sub-hc031\n",
      "sub-hc032\n",
      "sub-hc033\n",
      "sub-hc034\n",
      "sub-hc035\n",
      "sub-hc036\n",
      "sub-hc037\n",
      "sub-hc042\n",
      "sub-hc044\n",
      "sub-hc045\n",
      "sub-pp001\n",
      "sub-pp002\n",
      "sub-pp003\n",
      "sub-pp004\n",
      "sub-pp005\n",
      "sub-pp006\n",
      "sub-pp007\n",
      "sub-pp008\n",
      "sub-pp009\n",
      "sub-pp010\n",
      "sub-pp011\n",
      "sub-pp012\n",
      "sub-pp013\n",
      "sub-pp014\n",
      "sub-pp015\n",
      "sub-pp016\n",
      "response\n",
      "sub-hc001\n",
      "sub-hc002\n",
      "sub-hc003\n",
      "sub-hc004\n",
      "sub-hc005\n",
      "sub-hc006\n",
      "sub-hc007\n",
      "sub-hc008\n",
      "sub-hc009\n",
      "sub-hc010\n",
      "sub-hc011\n",
      "sub-hc012\n",
      "sub-hc014\n",
      "sub-hc015\n",
      "sub-hc016\n",
      "sub-hc017\n",
      "sub-hc019\n",
      "sub-hc020\n",
      "sub-hc021\n",
      "sub-hc022\n",
      "sub-hc023\n",
      "sub-hc024\n",
      "sub-hc025\n",
      "sub-hc026\n",
      "sub-hc028\n",
      "sub-hc029\n",
      "sub-hc030\n",
      "sub-hc031\n",
      "sub-hc032\n",
      "sub-hc033\n",
      "sub-hc034\n",
      "sub-hc035\n",
      "sub-hc036\n",
      "sub-hc037\n",
      "sub-hc042\n",
      "sub-hc044\n",
      "sub-hc045\n",
      "sub-pp001\n",
      "sub-pp002\n",
      "sub-pp003\n",
      "sub-pp004\n",
      "sub-pp005\n",
      "sub-pp006\n",
      "sub-pp007\n",
      "sub-pp008\n",
      "sub-pp009\n",
      "sub-pp010\n",
      "sub-pp011\n",
      "sub-pp012\n",
      "sub-pp013\n",
      "sub-pp014\n",
      "sub-pp015\n",
      "sub-pp016\n",
      "laplacian\n",
      "stimulus\n",
      "sub-hc001\n",
      "sub-hc002\n",
      "sub-hc003\n",
      "sub-hc004\n",
      "sub-hc005\n",
      "sub-hc006\n",
      "sub-hc007\n",
      "sub-hc008\n",
      "sub-hc009\n",
      "sub-hc010\n",
      "sub-hc011\n",
      "sub-hc012\n",
      "sub-hc014\n",
      "sub-hc015\n",
      "sub-hc016\n",
      "sub-hc017\n",
      "sub-hc019\n",
      "sub-hc020\n",
      "sub-hc021\n",
      "sub-hc022\n",
      "sub-hc023\n",
      "sub-hc024\n",
      "sub-hc025\n",
      "sub-hc026\n",
      "sub-hc028\n",
      "sub-hc029\n",
      "sub-hc030\n",
      "sub-hc031\n",
      "sub-hc032\n",
      "sub-hc033\n",
      "sub-hc034\n",
      "sub-hc035\n",
      "sub-hc036\n",
      "sub-hc037\n",
      "sub-hc042\n",
      "sub-hc044\n",
      "sub-hc045\n",
      "sub-pp001\n",
      "sub-pp002\n",
      "sub-pp003\n",
      "sub-pp004\n",
      "sub-pp005\n",
      "sub-pp006\n",
      "sub-pp007\n",
      "sub-pp008\n",
      "sub-pp009\n",
      "sub-pp010\n",
      "sub-pp011\n",
      "sub-pp012\n",
      "sub-pp013\n",
      "sub-pp014\n",
      "sub-pp015\n",
      "sub-pp016\n",
      "response\n",
      "sub-hc001\n",
      "sub-hc002\n",
      "sub-hc003\n",
      "sub-hc004\n",
      "sub-hc005\n",
      "sub-hc006\n",
      "sub-hc007\n",
      "sub-hc008\n",
      "sub-hc009\n",
      "sub-hc010\n",
      "sub-hc011\n",
      "sub-hc012\n",
      "sub-hc014\n",
      "sub-hc015\n",
      "sub-hc016\n",
      "sub-hc017\n",
      "sub-hc019\n",
      "sub-hc020\n",
      "sub-hc021\n",
      "sub-hc022\n",
      "sub-hc023\n",
      "sub-hc024\n",
      "sub-hc025\n",
      "sub-hc026\n",
      "sub-hc028\n",
      "sub-hc029\n",
      "sub-hc030\n",
      "sub-hc031\n",
      "sub-hc032\n",
      "sub-hc033\n",
      "sub-hc034\n",
      "sub-hc035\n",
      "sub-hc036\n",
      "sub-hc037\n",
      "sub-hc042\n",
      "sub-hc044\n",
      "sub-hc045\n",
      "sub-pp001\n",
      "sub-pp002\n",
      "sub-pp003\n",
      "sub-pp004\n",
      "sub-pp005\n",
      "sub-pp006\n",
      "sub-pp007\n",
      "sub-pp008\n",
      "sub-pp009\n",
      "sub-pp010\n",
      "sub-pp011\n",
      "sub-pp012\n",
      "sub-pp013\n",
      "sub-pp014\n",
      "sub-pp015\n",
      "sub-pp016\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for epo_class in ['base', 'laplacian']:\n",
    "    print(epo_class)\n",
    "    \n",
    "    if epo_class == 'base':\n",
    "        epo_root = '../data/derivatives/eeg_preprocessing/%s/epochs/%s_%s_cleaned-epo.fif'\n",
    "    else:\n",
    "        epo_root = '../data/derivatives/eeg_sensor/%s/lap/%s_%s_lap-epo.fif'\n",
    "        \n",
    "    for epo_type, epo_times in zip(epoch_types, epoch_times):\n",
    "        print(epo_type)\n",
    "\n",
    "        for subject in subjects:\n",
    "            if subject == 'group':\n",
    "                continue\n",
    "            print(subject)\n",
    "\n",
    "            # load subject behavior and epochs\n",
    "            sub_behavior = behavior[behavior.participant_id == subject]\n",
    "            f = epo_root % (subject, subject, epo_type)\n",
    "            epochs = read_epochs(f, verbose=False)\n",
    "\n",
    "            # interpolate the bad channels\n",
    "            epochs.interpolate_bads(reset_bads=True)\n",
    "\n",
    "            # drop bad trials from epochs and behavior\n",
    "            sub_behavior, epochs = drop_bad_trials(subject, sub_behavior, \n",
    "                                                   epochs, layout, epo_type)\n",
    "\n",
    "            # add event labels\n",
    "            epochs = add_events(epochs, sub_behavior)\n",
    "\n",
    "            tfrs = []\n",
    "            for event in conditions:\n",
    "                cond_epochs = epochs[event]\n",
    "\n",
    "                # remove evoked response\n",
    "                cond_epochs.subtract_evoked()\n",
    "\n",
    "                # compute tfr\n",
    "                power = tfr_morlet(cond_epochs, freqs=frequencies, \n",
    "                                   n_cycles=n_cycles, decim=5, \n",
    "                                   return_itc=False, average=False, n_jobs=2)\n",
    "\n",
    "                # crop out filter buffer\n",
    "                power.crop(epo_times[0], epo_times[1])\n",
    "                tfrs.append(power)\n",
    "\n",
    "            f = '../data/derivatives/eeg_sensor/%s/tfr/%s_%s_%s_raw-tfr.h5'\n",
    "            write_tfrs(f % (subject, subject, epo_type, epo_class), tfrs, \n",
    "                       overwrite=True)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Normalize Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-23T17:23:32.235848Z",
     "start_time": "2017-12-23T16:01:38.966608Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stimulus\n",
      "sub-hc001\n",
      "sub-hc002\n",
      "sub-hc003\n",
      "sub-hc004\n",
      "sub-hc005\n",
      "sub-hc006\n",
      "sub-hc007\n",
      "sub-hc008\n",
      "sub-hc009\n",
      "sub-hc010\n",
      "sub-hc011\n",
      "sub-hc012\n",
      "sub-hc014\n",
      "sub-hc015\n",
      "sub-hc016\n",
      "sub-hc017\n",
      "sub-hc019\n",
      "sub-hc020\n",
      "sub-hc021\n",
      "sub-hc022\n",
      "sub-hc023\n",
      "sub-hc024\n",
      "sub-hc025\n",
      "sub-hc026\n",
      "sub-hc028\n",
      "sub-hc029\n",
      "sub-hc030\n",
      "sub-hc031\n",
      "sub-hc032\n",
      "sub-hc033\n",
      "sub-hc034\n",
      "sub-hc035\n",
      "sub-hc036\n",
      "sub-hc037\n",
      "sub-hc042\n",
      "sub-hc044\n",
      "sub-hc045\n",
      "sub-pp001\n",
      "sub-pp002\n",
      "sub-pp003\n",
      "sub-pp004\n",
      "sub-pp005\n",
      "sub-pp006\n",
      "sub-pp007\n",
      "sub-pp008\n",
      "sub-pp009\n",
      "sub-pp010\n",
      "sub-pp011\n",
      "sub-pp012\n",
      "sub-pp013\n",
      "sub-pp014\n",
      "sub-pp015\n",
      "sub-pp016\n",
      "response\n",
      "sub-hc001\n",
      "sub-hc002\n",
      "sub-hc003\n",
      "sub-hc004\n",
      "sub-hc005\n",
      "sub-hc006\n",
      "sub-hc007\n",
      "sub-hc008\n",
      "sub-hc009\n",
      "sub-hc010\n",
      "sub-hc011\n",
      "sub-hc012\n",
      "sub-hc014\n",
      "sub-hc015\n",
      "sub-hc016\n",
      "sub-hc017\n",
      "sub-hc019\n",
      "sub-hc020\n",
      "sub-hc021\n",
      "sub-hc022\n",
      "sub-hc023\n",
      "sub-hc024\n",
      "sub-hc025\n",
      "sub-hc026\n",
      "sub-hc028\n",
      "sub-hc029\n",
      "sub-hc030\n",
      "sub-hc031\n",
      "sub-hc032\n",
      "sub-hc033\n",
      "sub-hc034\n",
      "sub-hc035\n",
      "sub-hc036\n",
      "sub-hc037\n",
      "sub-hc042\n",
      "sub-hc044\n",
      "sub-hc045\n",
      "sub-pp001\n",
      "sub-pp002\n",
      "sub-pp003\n",
      "sub-pp004\n",
      "sub-pp005\n",
      "sub-pp006\n",
      "sub-pp007\n",
      "sub-pp008\n",
      "sub-pp009\n",
      "sub-pp010\n",
      "sub-pp011\n",
      "sub-pp012\n",
      "sub-pp013\n",
      "sub-pp014\n",
      "sub-pp015\n",
      "sub-pp016\n",
      "stimulus\n",
      "sub-hc001\n",
      "sub-hc002\n",
      "sub-hc003\n",
      "sub-hc004\n",
      "sub-hc005\n",
      "sub-hc006\n",
      "sub-hc007\n",
      "sub-hc008\n",
      "sub-hc009\n",
      "sub-hc010\n",
      "sub-hc011\n",
      "sub-hc012\n",
      "sub-hc014\n",
      "sub-hc015\n",
      "sub-hc016\n",
      "sub-hc017\n",
      "sub-hc019\n",
      "sub-hc020\n",
      "sub-hc021\n",
      "sub-hc022\n",
      "sub-hc023\n",
      "sub-hc024\n",
      "sub-hc025\n",
      "sub-hc026\n",
      "sub-hc028\n",
      "sub-hc029\n",
      "sub-hc030\n",
      "sub-hc031\n",
      "sub-hc032\n",
      "sub-hc033\n",
      "sub-hc034\n",
      "sub-hc035\n",
      "sub-hc036\n",
      "sub-hc037\n",
      "sub-hc042\n",
      "sub-hc044\n",
      "sub-hc045\n",
      "sub-pp001\n",
      "sub-pp002\n",
      "sub-pp003\n",
      "sub-pp004\n",
      "sub-pp005\n",
      "sub-pp006\n",
      "sub-pp007\n",
      "sub-pp008\n",
      "sub-pp009\n",
      "sub-pp010\n",
      "sub-pp011\n",
      "sub-pp012\n",
      "sub-pp013\n",
      "sub-pp014\n",
      "sub-pp015\n",
      "sub-pp016\n",
      "response\n",
      "sub-hc001\n",
      "sub-hc002\n",
      "sub-hc003\n",
      "sub-hc004\n",
      "sub-hc005\n",
      "sub-hc006\n",
      "sub-hc007\n",
      "sub-hc008\n",
      "sub-hc009\n",
      "sub-hc010\n",
      "sub-hc011\n",
      "sub-hc012\n",
      "sub-hc014\n",
      "sub-hc015\n",
      "sub-hc016\n",
      "sub-hc017\n",
      "sub-hc019\n",
      "sub-hc020\n",
      "sub-hc021\n",
      "sub-hc022\n",
      "sub-hc023\n",
      "sub-hc024\n",
      "sub-hc025\n",
      "sub-hc026\n",
      "sub-hc028\n",
      "sub-hc029\n",
      "sub-hc030\n",
      "sub-hc031\n",
      "sub-hc032\n",
      "sub-hc033\n",
      "sub-hc034\n",
      "sub-hc035\n",
      "sub-hc036\n",
      "sub-hc037\n",
      "sub-hc042\n",
      "sub-hc044\n",
      "sub-hc045\n",
      "sub-pp001\n",
      "sub-pp002\n",
      "sub-pp003\n",
      "sub-pp004\n",
      "sub-pp005\n",
      "sub-pp006\n",
      "sub-pp007\n",
      "sub-pp008\n",
      "sub-pp009\n",
      "sub-pp010\n",
      "sub-pp011\n",
      "sub-pp012\n",
      "sub-pp013\n",
      "sub-pp014\n",
      "sub-pp015\n",
      "sub-pp016\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# cache stimulus baseline periods \n",
    "baselines = {}\n",
    "\n",
    "for epo_class in ['base', 'laplacian']:\n",
    "    for epo_type, epo_times in zip(epoch_types, epoch_times):\n",
    "        print(epo_type)\n",
    "\n",
    "        group = {'incongruent': [], 'congruent': []}\n",
    "        for subject in subjects:\n",
    "            if subject == 'group':\n",
    "                continue\n",
    "            print(subject)\n",
    "\n",
    "            f = '../data/derivatives/eeg_sensor/%s/tfr/%s_%s_%s_raw-tfr.h5'\n",
    "            tfrs = read_tfrs(f % (subject, subject, epo_type, epo_class))\n",
    "\n",
    "            if epo_type == 'stimulus':\n",
    "                baselines[subject] = {'incongruent': (-.5, -.1), \n",
    "                                      'congruent': (-.5, -.1)}\n",
    "\n",
    "            norm_tfrs = []\n",
    "            for i, c in enumerate(conditions):\n",
    "\n",
    "                tfr, baseline = baseline_normalize(tfrs[i], \n",
    "                                                   baselines[subject][c],\n",
    "                                                   func=np.median, \n",
    "                                                   method='classic')\n",
    "                norm_tfrs.append(tfr)\n",
    "                group[c].append(tfr)\n",
    "                baselines[subject][c] = baseline\n",
    "\n",
    "\n",
    "            f = '../data/derivatives/eeg_sensor/%s/tfr/%s_%s_%s_norm-tfr.h5'\n",
    "            write_tfrs(f % (subject, subject, epo_type, epo_class), norm_tfrs, \n",
    "                       overwrite=True)\n",
    "\n",
    "        group_tfrs = [grand_average(group[c]) for c in conditions]\n",
    "        f = '../data/derivatives/eeg_sensor/group/tfr/group_%s_%s_norm-tfr.h5'\n",
    "        write_tfrs(f % (epo_type, epo_class), group_tfrs, overwrite=True)\n",
    "\n",
    "del baselines\n",
    "del group_tfrs\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize TFR Power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFR Power Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-03T01:08:43.288569Z",
     "start_time": "2018-01-03T01:08:36.386063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f460417d5c04eea97b93b73153aa159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(Dropdown(description=u'subject', options=('group', 'sub-hc001', 'sub-hc002', 'sub-hc003', 'sub-hc004', 'sub-hc005', 'sub-hc006', 'sub-hc007', 'sub-hc008', 'sub-hc009', 'sub-hc010', 'sub-hc011', 'sub-hc012', 'sub-hc014', 'sub-hc015', 'sub-hc016', 'sub-hc017', 'sub-hc019', 'sub-hc020', 'sub-hc021', 'sub-hc022', 'sub-hc023', 'sub-hc024', 'sub-hc025', 'sub-hc026', 'sub-hc028', 'sub-hc029', 'sub-hc030', 'sub-hc031', 'sub-hc032', 'sub-hc033', 'sub-hc034', 'sub-hc035', 'sub-hc036', 'sub-hc037', 'sub-hc042', 'sub-hc044', 'sub-hc045', 'sub-pp001', 'sub-pp002', 'sub-pp003', 'sub-pp004', 'sub-pp005', 'sub-pp006', 'sub-pp007', 'sub-pp008', 'sub-pp009', 'sub-pp010', 'sub-pp011', 'sub-pp012', 'sub-pp013', 'sub-pp014', 'sub-pp015', 'sub-pp016'), value='group'), Dropdown(description=u'ch', options=('Fp1', 'Fpz', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8', 'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8', 'FT9', 'FT7', 'FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6', 'FT8', 'FT10', 'T9', 'T7', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'T8', 'T10', 'TP9', 'TP7', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6', 'TP8', 'TP10', 'P9', 'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8', 'P10', 'PO7', 'PO3', 'P0z', 'PO4', 'PO8', 'O1', 'Oz', 'O2', 'Iz'), value='Fp1'), FloatSlider(value=2.0, description=u'lim', max=4.0, min=0.5, step=0.5), Dropdown(description=u'epo_class', options=('base', 'laplacian'), value='base'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_tfr_heatmap(subject, ch, lim, epo_class, behavior):\n",
    "    \n",
    "    exclusions = ['fast_rt', 'no_response', 'error', 'post_error']\n",
    "    sub_behavior = behavior.loc[np.where(np.sum(behavior[exclusions], \n",
    "                                            axis=1) == 0)[0], :]\n",
    "    if subject != 'group':\n",
    "        sub_behavior = sub_behavior.loc[sub_behavior.participant_id == subject, :]\n",
    "    sns.set(style='white', font_scale=2)\n",
    "    plt.close('all')\n",
    "\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(24, 16))\n",
    "    \n",
    "    \n",
    "    for i, epo_type in enumerate(epoch_types):\n",
    "        \n",
    "        f = '../data/derivatives/eeg_sensor/%s/tfr/%s_%s_%s_norm-tfr.h5'\n",
    "        tfrs = read_tfrs(f % (subject, subject, epo_type, epo_class))\n",
    "\n",
    "        powers = []\n",
    "        for j, c in enumerate(conditions):\n",
    "            \n",
    "            power = tfrs[j]\n",
    "            power.pick_channels([ch])\n",
    "            ax = axs[i, j]\n",
    "            rts = [sub_behavior[sub_behavior.trial_type == c].response_time]\n",
    "            rt_colors = [colors[j]] \n",
    "            if epo_type == 'stimulus':\n",
    "                ax = power_heatmap(power, ax, lim, rts, rt_colors)\n",
    "            else:\n",
    "                ax = power_heatmap(power, ax, lim)\n",
    "            ax.set_title('%s %s-locked' % (c, epo_type))\n",
    "                \n",
    "\n",
    "        ax = axs[i, 2]\n",
    "        power = tfrs[0] - tfrs[1] \n",
    "        power.pick_channels([ch])\n",
    "        rts = [sub_behavior[sub_behavior.trial_type == c].response_time for c in conditions]\n",
    "        rt_colors = [colors[0], colors[1]]\n",
    "        if epo_type == 'stimulus':\n",
    "            ax = power_heatmap(power, ax, lim, rts, rt_colors)\n",
    "        else:\n",
    "            ax = power_heatmap(power, ax, lim)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=.92)\n",
    "    plt.suptitle('%s %s TFR Heatmaps (Color Limit: +- %s)' % (subject, ch, lim), \n",
    "                 fontsize=24)\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_tfr_heatmap, subject=subjects, ch=CH_NAMES, \n",
    "         lim=(.5, 4, .5), epo_class=['base', 'laplacian'], \n",
    "         behavior=fixed(behavior));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFR Power Topomaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T16:29:00.153144Z",
     "start_time": "2017-12-27T16:28:57.311419Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5c65b945044cbda68858d5892126b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(Dropdown(description=u'subject', options=('group', 'group', 'sub-hc001', 'sub-hc002', 'sub-hc003', 'sub-hc004', 'sub-hc005', 'sub-hc006', 'sub-hc007', 'sub-hc008', 'sub-hc009', 'sub-hc010', 'sub-hc011', 'sub-hc012', 'sub-hc014', 'sub-hc015', 'sub-hc016', 'sub-hc017', 'sub-hc019', 'sub-hc020', 'sub-hc021', 'sub-hc022', 'sub-hc023', 'sub-hc024', 'sub-hc025', 'sub-hc026', 'sub-hc028', 'sub-hc029', 'sub-hc030', 'sub-hc031', 'sub-hc032', 'sub-hc033', 'sub-hc034', 'sub-hc035', 'sub-hc036', 'sub-hc037', 'sub-hc042', 'sub-hc044', 'sub-hc045', 'sub-pp001', 'sub-pp002', 'sub-pp003', 'sub-pp004', 'sub-pp005', 'sub-pp006', 'sub-pp007', 'sub-pp008', 'sub-pp009', 'sub-pp010', 'sub-pp011', 'sub-pp012', 'sub-pp013', 'sub-pp014', 'sub-pp015', 'sub-pp016'), value='group'), Dropdown(description=u'epo_type', options=('response', 'stimulus'), value='response'), Dropdown(description=u'epo_class', options=('base', 'laplacian'), value='base'), Dropdown(description=u'time', options=(-1.0, -0.98999999999999999, -0.97999999999999998, -0.96999999999999997, -0.95999999999999996, -0.94999999999999996, -0.93999999999999995, -0.92999999999999994, -0.91999999999999993, -0.90999999999999992, -0.89999999999999991, -0.8899999999999999, -0.87999999999999989, -0.86999999999999988, -0.85999999999999988, -0.84999999999999987, -0.83999999999999986, -0.82999999999999985, -0.81999999999999984, -0.80999999999999983, -0.79999999999999982, -0.78999999999999981, -0.7799999999999998, -0.7699999999999998, -0.75999999999999979, -0.74999999999999978, -0.73999999999999977, -0.72999999999999976, -0.71999999999999975, -0.70999999999999974, -0.69999999999999973, -0.68999999999999972, -0.67999999999999972, -0.66999999999999971, -0.6599999999999997, -0.64999999999999969, -0.63999999999999968, -0.62999999999999967, -0.61999999999999966, -0.60999999999999965, -0.59999999999999964, -0.58999999999999964, -0.57999999999999963, -0.56999999999999962, -0.55999999999999961, -0.5499999999999996, -0.53999999999999959, -0.52999999999999958, -0.51999999999999957, -0.50999999999999956, -0.49999999999999956, -0.48999999999999955, -0.47999999999999954, -0.46999999999999953, -0.45999999999999952, -0.44999999999999951, -0.4399999999999995, -0.42999999999999949, -0.41999999999999948, -0.40999999999999948, -0.39999999999999947, -0.38999999999999946, -0.37999999999999945, -0.36999999999999944, -0.35999999999999943, -0.34999999999999942, -0.33999999999999941, -0.3299999999999994, -0.3199999999999994, -0.30999999999999939, -0.29999999999999938, -0.28999999999999937, -0.27999999999999936, -0.26999999999999935, -0.25999999999999934, -0.24999999999999933, -0.23999999999999932, -0.22999999999999932, -0.21999999999999931, -0.2099999999999993, -0.19999999999999929, -0.18999999999999928, -0.17999999999999927, -0.16999999999999926, -0.15999999999999925, -0.14999999999999925, -0.13999999999999924, -0.12999999999999923, -0.11999999999999922, -0.10999999999999921, -0.099999999999999201, -0.089999999999999192, -0.079999999999999183, -0.069999999999999174, -0.059999999999999165, -0.049999999999999156, -0.039999999999999147, -0.029999999999999138, -0.01999999999999913, -0.0099999999999991207, 8.8817841970012523e-16, 0.010000000000000897, 0.020000000000000906, 0.030000000000000915, 0.040000000000000924, 0.050000000000000933, 0.060000000000000941, 0.07000000000000095, 0.080000000000000959, 0.090000000000000968, 0.10000000000000098, 0.11000000000000099, 0.12000000000000099, 0.130000000000001, 0.14000000000000101, 0.15000000000000102, 0.16000000000000103, 0.17000000000000104, 0.18000000000000105, 0.19000000000000106, 0.20000000000000107, 0.21000000000000107, 0.22000000000000108, 0.23000000000000109, 0.2400000000000011, 0.25000000000000111, 0.26000000000000112, 0.27000000000000113, 0.28000000000000114, 0.29000000000000115, 0.30000000000000115, 0.31000000000000116, 0.32000000000000117, 0.33000000000000118, 0.34000000000000119, 0.3500000000000012, 0.36000000000000121, 0.37000000000000122, 0.38000000000000123, 0.39000000000000123, 0.40000000000000124, 0.41000000000000125, 0.42000000000000126, 0.43000000000000127, 0.44000000000000128, 0.45000000000000129, 0.4600000000000013, 0.47000000000000131, 0.48000000000000131, 0.49000000000000132, 0.50000000000000133, 0.51000000000000134, 0.52000000000000135, 0.53000000000000136, 0.54000000000000137, 0.55000000000000138, 0.56000000000000139, 0.57000000000000139, 0.5800000000000014, 0.59000000000000141, 0.60000000000000142, 0.61000000000000143, 0.62000000000000144, 0.63000000000000145, 0.64000000000000146, 0.65000000000000147, 0.66000000000000147, 0.67000000000000148, 0.68000000000000149, 0.6900000000000015, 0.70000000000000151, 0.71000000000000152, 0.72000000000000153, 0.73000000000000154, 0.74000000000000155, 0.75000000000000155, 0.76000000000000156, 0.77000000000000157, 0.78000000000000158, 0.79000000000000159, 0.8000000000000016, 0.81000000000000161, 0.82000000000000162, 0.83000000000000163, 0.84000000000000163, 0.85000000000000164, 0.86000000000000165, 0.87000000000000166, 0.88000000000000167, 0.89000000000000168, 0.90000000000000169, 0.9100000000000017, 0.92000000000000171, 0.93000000000000171, 0.94000000000000172, 0.95000000000000173, 0.96000000000000174, 0.97000000000000175, 0.98000000000000176, 0.99000000000000177, 1.0000000000000018, 1.0100000000000016, 1.0200000000000018, 1.030000000000002, 1.0400000000000018, 1.0500000000000016, 1.0600000000000018, 1.0700000000000021, 1.0800000000000018, 1.0900000000000016, 1.1000000000000019, 1.1100000000000021, 1.1200000000000019, 1.1300000000000017, 1.1400000000000019, 1.1500000000000021, 1.1600000000000019, 1.1700000000000017, 1.1800000000000019, 1.1900000000000022, 1.200000000000002, 1.2100000000000017, 1.220000000000002, 1.2300000000000022, 1.240000000000002, 1.2500000000000018, 1.260000000000002, 1.2700000000000022, 1.280000000000002, 1.2900000000000018, 1.300000000000002, 1.3100000000000023, 1.3200000000000021, 1.3300000000000018, 1.3400000000000021, 1.3500000000000023, 1.3600000000000021, 1.3700000000000019, 1.3800000000000021, 1.3900000000000023, 1.4000000000000021, 1.4100000000000019, 1.4200000000000021, 1.4300000000000024, 1.4400000000000022, 1.450000000000002, 1.4600000000000022, 1.4700000000000024, 1.4800000000000022, 1.490000000000002, 1.5000000000000022, 1.5100000000000025, 1.5200000000000022, 1.530000000000002, 1.5400000000000023, 1.5500000000000025, 1.5600000000000023, 1.5700000000000021, 1.5800000000000023, 1.5900000000000025, 1.6000000000000023, 1.6100000000000021, 1.6200000000000023, 1.6300000000000026, 1.6400000000000023, 1.6500000000000021, 1.6600000000000024, 1.6700000000000026, 1.6800000000000024, 1.6900000000000022, 1.7000000000000024, 1.7100000000000026, 1.7200000000000024, 1.7300000000000022, 1.7400000000000024), value=-1.0), Dropdown(description=u'fmin', options=(2.0, 2.2488744551392053, 2.5287181574888282, 2.8433848343116517, 3.1972077600068474, 3.5950594296261187, 4.0424186579967492, 4.5454460284734983, 5.1110687303240008, 5.7470759530432085, 6.4622261512718371, 7.2663676574638858, 8.1705743032601212, 9.1872979172092464, 10.330539798882747, 11.616043530753158, 13.061511783047896, 14.686850097198077, 16.514441005023748, 18.569452258550662, 20.880183415090805, 23.478455550409507, 26.40004946671861, 29.685198430057429, 33.379142222547301, 37.532750139372546, 42.203221509778693, 47.454873388961353, 53.360026268150207, 60.0), value=2.0), Dropdown(description=u'fmax', options=(2.0, 2.2488744551392053, 2.5287181574888282, 2.8433848343116517, 3.1972077600068474, 3.5950594296261187, 4.0424186579967492, 4.5454460284734983, 5.1110687303240008, 5.7470759530432085, 6.4622261512718371, 7.2663676574638858, 8.1705743032601212, 9.1872979172092464, 10.330539798882747, 11.616043530753158, 13.061511783047896, 14.686850097198077, 16.514441005023748, 18.569452258550662, 20.880183415090805, 23.478455550409507, 26.40004946671861, 29.685198430057429, 33.379142222547301, 37.532750139372546, 42.203221509778693, 47.454873388961353, 53.360026268150207, 60.0), value=2.0), Dropdown(description=u'col_limit', options=(0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5), value=0.5), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_topomap(subject, epo_type, epo_class, time, fmin, fmax, col_limit):\n",
    "    plt.close('all')\n",
    "    f = '../data/derivatives/eeg_sensor/%s/tfr/%s_%s_%s_norm-tfr.h5'\n",
    "    tfrs = read_tfrs(f % (subject, subject, epo_type, epo_class))\n",
    "\n",
    "    f, axs = plt.subplots(1, 3, figsize=(24, 6)) \n",
    "    \n",
    "    for i, tfr in enumerate(tfrs):\n",
    "        tfr.plot_topomap(tmin=time, tmax=time + .005,\n",
    "                         fmin=fmin, fmax=fmax, axes=axs[i], colorbar=True, \n",
    "                         show=False, vmin=-col_limit, vmax=col_limit)\n",
    "        axs[i].set_xlabel(conditions[i])\n",
    "        \n",
    "    diff = tfrs[0] - tfrs[1]\n",
    "    diff.plot_topomap(tmin=time, tmax=time + .005,\n",
    "                      fmin=fmin, fmax=fmax, axes=axs[2], colorbar=True, \n",
    "                      show=False, vmin=-col_limit, vmax=col_limit)\n",
    "    axs[2].set_xlabel('i-c')\n",
    "    plt.suptitle('%.2f s' % time)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "interact(plot_topomap, subject=['group'] + subjects, \n",
    "         epo_type=['response', 'stimulus'],\n",
    "         epo_class=['base', 'laplacian'],\n",
    "         time=np.arange(-1, 1.75, .01), \n",
    "         fmin=frequencies, fmax=frequencies,\n",
    "         col_limit=np.arange(.5, 5, .5));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "775px",
    "left": "0px",
    "right": "1496.28px",
    "top": "106px",
    "width": "280px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
