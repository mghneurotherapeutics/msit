{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FMRI Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality Control with MRIQC\n",
    "\n",
    "We use the Poldrack Lab's <a href=\"https://mriqc.readthedocs.io/en/0.10.3/\"> mriqc v0.10.3</a> for quality control of the scans. MRIQC is a great tool that performs automatic extraction of qc metric and generates standardized subject reports as well as aggregate group reports. This allows us to use the group reports to first screen for outlier scans and then use the participant level reports to determine if these outliers are candidates for exclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Reports\n",
    "\n",
    "This cell first generates individual reports and qc measures for each participant. It then generates group aggregate reports that are used to determine outlier candidates for exclusion as documented in the cell below.\n",
    "\n",
    "Before running, one should also change the fd threshold to match the desired threshold to generate motion statistics with for the BOLD data. Finally, one should change the --n_procs argument based on their available computational resources.\n",
    "\n",
    "Warning: This cell takes several hours to run with 10 processes allocated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T13:38:12.877401Z",
     "start_time": "2018-05-24T13:38:12.826570Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker run --rm -u 3950117:1047 -v /autofs/space/cassia_001/users/matt/msit/data:/data:ro -v /autofs/space/cassia_001/users/matt/msit/data/derivatives/mriqc:/out -v /autofs/space/cassia_001/users/matt/msit/data/derivatives/mriqc:/work poldracklab/mriqc:0.10.3 /data /out participant -w /work --no-sub --verbose-reports --write-graph --ica --n_procs=10 --fft-spikes-detector --fd_thres 0.9\n",
      "docker run --rm -u 3950117:1047 -v /autofs/space/cassia_001/users/matt/msit/data:/data:ro -v /autofs/space/cassia_001/users/matt/msit/data/derivatives/mriqc:/out -v /autofs/space/cassia_001/users/matt/msit/data/derivatives/mriqc:/work poldracklab/mriqc:0.10.3 /data /out group -w /work\n"
     ]
    }
   ],
   "source": [
    "from subprocess import call, check_output\n",
    "import os\n",
    "\n",
    "# bids path (absolute path needed for docker) \n",
    "data_path = '/autofs/space/cassia_001/users/matt/msit/data'\n",
    "\n",
    "# mriqc output path (absolute path needed for docker) \n",
    "# this must be created ahead of time or it will be created with root permissions\n",
    "mriqc_path = '%s/derivatives/mriqc' % data_path\n",
    "if not os.path.exists(mriqc_path):\n",
    "    os.makedirs(mriqc_path)\n",
    "\n",
    "# user and group id to set permissions on output appropriately\n",
    "uid = check_output(['id', '-u'])[:-1]\n",
    "gid = check_output(['id', '-G']).split(' ')[-1][:-1]\n",
    "\n",
    "# set to desired threshold\n",
    "fd_thres = '0.9'\n",
    "\n",
    "docker_command = ['docker',\n",
    "                  'run',\n",
    "                  '--rm',\n",
    "                  '-u', '%s:%s' % (uid, gid),\n",
    "                  '-v', '%s:/data:ro' % data_path,\n",
    "                  '-v', '%s:/out' % mriqc_path,\n",
    "                  '-v', '%s:/work' % mriqc_path,\n",
    "                  'poldracklab/mriqc:0.10.3',\n",
    "                  '/data', '/out',\n",
    "                  'participant',\n",
    "                  '-w', '/work',\n",
    "                  '--no-sub',\n",
    "                  '--verbose-reports',\n",
    "                  '--write-graph',\n",
    "                  '--ica',\n",
    "                  '--n_procs=10',\n",
    "                  '--fft-spikes-detector',\n",
    "                  '--fd_thres', fd_thres]\n",
    "\n",
    "print(' '.join(docker_command))\n",
    "call(docker_command)\n",
    "\n",
    "# generate group reports\n",
    "docker_command = ['docker',\n",
    "                  'run',\n",
    "                  '--rm',\n",
    "                  '-u', '%s:%s' % (uid, gid),\n",
    "                  '-v', '%s:/data:ro' % data_path,\n",
    "                  '-v', '%s:/out' % mriqc_path,\n",
    "                  '-v', '%s:/work' % mriqc_path,\n",
    "                  'poldracklab/mriqc:0.10.3',\n",
    "                  '/data', '/out',\n",
    "                  'group',\n",
    "                  '-w', '/work']\n",
    "\n",
    "print(' '.join(docker_command))\n",
    "call(docker_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations & Subject Exclusions\n",
    "\n",
    "We use the group reports for the T1 and BOLD scans to determine exclusions:\n",
    "\n",
    "- <a href=\"../data/derivatives/mriqc/reports/T1w_group.html\"> T1 Group Report</a>\n",
    "- <a href=\"../data/derivatives/mriqc/reports/bold_group.html\"> BOLD Group Report</a>\n",
    "\n",
    "T1 Observations:\n",
    "* pre-scan normalize was off for the T1 on the bay 4 prisma\n",
    "* The newer prisma has much better noise quality than the older trio scanners as measured by EFC (measure of ghosting/blurring) & FBER (relative energy within brain relative to background). Hard to actually see this however due to lack of pre-scan normalize for the prisma scans. This difference also appears whenever anything is normalized by background noise (such as SNRD).\n",
    "* The CJV & CNR measures appeared to be inversely related with heavy tails. The tails seemed ok and not grounds for exclusion. It seems it may have been sensitive to the amount of gyral folding and hence the discriminability of grey and white matter?\n",
    "* A few other outliers, but most related to wrap around, ghosting, etc. that did not affect the brain itself (apart from exclusions below).\n",
    "\n",
    "BOLD Observations:\n",
    "* A few with fairly bad motion. Leaving in to see if scrubbing/correction can help.\n",
    "* sub-hc045 has weird frontal dropout (not present in T1). Leaving in to see if b0 correction helps. Outlier on FWHM y.\n",
    "\n",
    "Subject Exclusions:\n",
    "* sub-hc037: Appears to not have had anterior head coil in. Caught by being outlier in FWHM y for T1 and bold.\n",
    "* sub-hc018: Has a 10 mm motion. Outlier on FD and AOR.\n",
    "* sub-hc020: Extremely bad motion. Caught as outlier on AOR and Average FD.\n",
    "* sub-hc047: Really bad motion and really bad distortion/dropout in the frontal regions. Caught as outlier on Average FD and FWHM y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from utils import exclude_subjects\n",
    "\n",
    "exclude_subjects(['sub-hc018', 'sub-hc020', 'sub-hc037', 'sub-hc047'], 'fmri')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing with FMRIPREP\n",
    "\n",
    "Here we use the Poldrack lab's <a href=\"https://fmriprep.readthedocs.io/en/1.0.8/index.html\">fmriprep v1.0.8</a> software package to perform preprocessing of the MSIT BOLD data. fmriprep is an awesome tool built off of nipype that combines different preprocessing steps across multiple packages into a single preprocessing workflow. \n",
    "\n",
    "The full workflow is detailed <a href=\"https://fmriprep.readthedocs.io/en/1.0.8/workflows.html#\">here</a>. The primary components of the workflow are:\n",
    "- brainmask generation\n",
    "- freesurfer reconstruction\n",
    "- BOLD motion correction\n",
    "- BOLD B0 field distortion correction\n",
    "- Slice time correction\n",
    "- Spatial normalization\n",
    "- Generation of confound signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run FMRIPREP \n",
    "\n",
    "We used fmriprep's docker image to install and run fmriprep following the fmriprep documentation's instructions. This will require one to have docker installed. With docker installed and the image downloaded, the commands below should then work.\n",
    "\n",
    "Warning: Each fmriprep run is quite computationally intensive. A single run will take a few GB of memory and will need to run overnight. Running all of our subjects serially would take > 50 days. To speed up this process, we run multiple subjects in parallel. With our computing resources we were able to run 10 subjects at a time reducing the computation time to ~5 days. The script below automatically detects the number of fmriprep processes running and adds new one as cores open up so that the number of cores being used for processing is always 10 or less. One can lower or raise the number of cores as allowed by their computing resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import Popen\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from utils import select_subjects\n",
    "\n",
    "# change if necessary\n",
    "num_cores = 10\n",
    "\n",
    "# user and group id to set permissions on output appropriately\n",
    "uid = check_output(['id', '-u'])[:-1]\n",
    "gid = check_output(['id', '-G']).split(' ')[-1][:-1]\n",
    "\n",
    "# bids path (absolute path needed for docker) \n",
    "data_path = '/autofs/space/cassia_001/users/matt/msit/data'\n",
    "\n",
    "# fmriprep output path (absolute path needed for docker) \n",
    "# this must be created ahead of time or it will be created with root permissions\n",
    "# you must also have placed a valid fs license file in this directory\n",
    "fmriprep_path = '%s/derivatives/fmriprep' % data_path\n",
    "if not os.path.exists(fmriprep_path):\n",
    "    os.makedirs(fmriprep_path)\n",
    "\n",
    "# get the subjects\n",
    "subjects = select_subjects('fmri', [])\n",
    "num_sub = len(subjects)\n",
    "sub_num = 1\n",
    "    \n",
    "# fmriprep docker command template\n",
    "docker_command = ['docker', 'run', '--rm',\n",
    "                  '-u', '%s:%s' % (uid, gid),\n",
    "                  '-v', '%s:/data:ro' % data_path,\n",
    "                  '-v', '%s:/out' % fmriprep_path,\n",
    "                  '-v', '%s:/work' % fmriprep_path,\n",
    "                  '-w', '/work',\n",
    "                  'poldracklab/fmriprep:1.0.8',\n",
    "                  '/data', '/out',\n",
    "                  'participant',\n",
    "                  '--participant_label', 'replaced with subject id',\n",
    "                  '-t', 'msit',\n",
    "                  '-w', '/work',\n",
    "                  '--omp-nthreads', '1',\n",
    "                  '--nthreads', '1',\n",
    "                  '--output-space', 'fsaverage', 'fsnative', \n",
    "                  'T1w', 'template',\n",
    "                  '--fs-license-file', '/out/fs_license.txt']\n",
    "\n",
    "running_procs = []\n",
    "running_subs = []\n",
    "\n",
    "while sub_num <= num_sub:\n",
    "    \n",
    "    if len(running_procs) < num_cores:\n",
    "        subject = subjects[sub_num - 1]\n",
    "        print('Starting Subject # %d: %s' % (sub_num, subject))\n",
    "        \n",
    "        # start new fmriprep on available core\n",
    "        docker_command[18] = subject\n",
    "        running_procs.append(Popen(docker_command))\n",
    "        running_subs.append((subject, sub_num))\n",
    "        print(' '.join(docker_command))\n",
    "        \n",
    "        sub_num += 1\n",
    "    else:\n",
    "        # run through existing fmriprep processes to see if \n",
    "        # any have completed, if so remove from running list\n",
    "        running_procs_copy = []\n",
    "        running_subs_copy = []\n",
    "        for r, s in zip(running_procs, running_subs):\n",
    "            if r.poll() is None:\n",
    "                running_procs_copy.append(r)\n",
    "                running_subs_copy.append(s)\n",
    "            else:\n",
    "                print('Finished Subject # %d: %s' % (s[1], s[0]))\n",
    "        running_procs = running_procs_copy\n",
    "        running_subs = running_subs_copy\n",
    "        \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the computations above are finished, you should run this quick cell here to clean up the directory output from fmriprep. This results in a separate fmriprep derivatives folder with the fmriprep results inside and a separate Freesurfer recons derivatives folder (labeled freesurfer) with the Freesurfer reconstructions inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd ../data/derivatives/fmriprep\n",
    "mv fmriprep/* .\n",
    "rm -r fmriprep\n",
    "mv freesurfer .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations & Subject Exclusions\n",
    "\n",
    "Here we do a sanity check through the output report for each subject to make sure nothing really bad was off. \n",
    "\n",
    "<a href=\"file:///autofs/space/cassia_001/users/matt/msit/data/derivatives/fmriprep/sub-hc016.html\"> Here is a link to an Example Report </a>\n",
    "\n",
    "Observations:\n",
    "* All looked good except the additional exclusions denoted below and those in the QC exclusions section.\n",
    "\n",
    "Exclusions:\n",
    "* sub-hc045: Serious frontal signal dropout extending quite far back. Would make inference in large parts of frontal cortex intractable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from utils import exclude_subjects\n",
    "\n",
    "exclude_subjects(['sub-hc045'], 'fmri')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FMRIPREP to FSFAST Interface\n",
    "\n",
    "The final step in our preprocessing pipeline is to coerce the outputs from fmriprep into the fsfast file structure so that we can run 1st levels using fsfast. We also perform the final preprocessing step which involves spatially smoothing the data to help increase our SNR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T18:42:45.307879Z",
     "start_time": "2018-05-10T12:29:27.955436Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# source freesurfer\n",
    "export FREESURFER_HOME=/usr/local/freesurfer/stable6_0_0\n",
    "source ${FREESURFER_HOME}/SetUpFreeSurfer.sh\n",
    "\n",
    "# full path to recons folder\n",
    "export SUBJECTS_DIR=/autofs/space/cassia_001/users/matt/msit/data/derivatives/freesurfer\n",
    "\n",
    "fwhm=4\n",
    "tr=1750\n",
    "\n",
    "fmriprep_dir=/autofs/space/cassia_001/users/matt/msit/data/derivatives/fmriprep\n",
    "fsfast_dir=/autofs/space/cassia_001/users/matt/msit/data/derivatives/fsfast\n",
    "\n",
    "# subjects=$(find $fmriprep_dir -type d -name \"sub-*\" -printf \"%f\\n\" -maxdepth 1)\n",
    "subjects=$(cat $fsfast_dir/subjects)\n",
    "for subject in $subjects\n",
    "do\n",
    "    echo $subject\n",
    "    \n",
    "    # set up folder\n",
    "    run_dir=$fsfast_dir/$subject/msit/001\n",
    "    mkdir -p $run_dir/masks\n",
    "    echo $subject > $fsfast_dir/$subject/subjectname\n",
    "    fmp_dir=$fmriprep_dir/$subject/func\n",
    "    fmp_stem=${subject}_task-msit_bold\n",
    "    \n",
    "    # copy over functional volume and reinforce tr\n",
    "    # we copy the same twice as f and fmcpr since fsfast requires\n",
    "    # files named this way at different stages that we're skipping\n",
    "    in_stem=${fmp_stem}_space-T1w_preproc\n",
    "    cp $fmp_dir/${in_stem}.nii.gz $run_dir/f.nii.gz\n",
    "    mri_convert $run_dir/f.nii.gz  \\\n",
    "                $run_dir/f.nii.gz -tr $tr\n",
    "    cp $run_dir/f.nii.gz $run_dir/fmcpr.nii.gz\n",
    "                \n",
    "    # convert surface files\n",
    "    declare -a hemis=(\"l\" \"r\")\n",
    "    for hemi in \"${hemis[@]}\"\n",
    "    do\n",
    "       uphemi=$(echo $hemi| awk '{print toupper($0)}')\n",
    "       out_stem=fmcpr.sm${fwhm}.fsaverage.${hemi}h\n",
    "       in_stem=${fmp_stem}_space-fsaverage.${uphemi}.func\n",
    "       \n",
    "       mri_surf2surf --srcsubject fsaverage --trgsubject fsaverage \\\n",
    "                     --sval $fmp_dir/${in_stem}.gii \\\n",
    "                     --tval $run_dir/${out_stem}.nii.gz \\\n",
    "                     --fwhm-trg $fwhm --hemi ${hemi}h\n",
    "       mri_convert $run_dir/${out_stem}.nii.gz  \\\n",
    "                   $run_dir/${out_stem}.nii.gz -tr $tr\n",
    "    done\n",
    "    \n",
    "    # sample volume file to tal space \n",
    "    # this will re-create\n",
    "    cd $fsfast_dir\n",
    "    preproc-sess -per-run -s $subject -mni305 -fwhm $fwhm -nostc -nomc \\\n",
    "                 -fsd msit\n",
    "    \n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
